

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Module: HDFS &mdash; chpldoc 0.0.1 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700&subset=latin,cyrillic' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="chpldoc 0.0.1 documentation" href="../../index.html"/>
        <link rel="next" title="Module: HDFSiterator" href="HDFSiterator.html"/>
        <link rel="prev" title="Module: GMP" href="GMP.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="../../index.html" class="fa fa-home"> chpldoc</a>
        
        
<?php   // Variables given by sphinx 
   $chplTitle = "1.11";   $pagename = "./modules/standard/HDFS";   include "../../versionButton.php";   ?>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">chpldoc documentation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="AdvancedIters.html">Module: AdvancedIters</a></li>
<li class="toctree-l1"><a class="reference internal" href="Assert.html">Module: Assert</a></li>
<li class="toctree-l1"><a class="reference internal" href="BitOps.html">Module: BitOps</a></li>
<li class="toctree-l1"><a class="reference internal" href="Buffers.html">Module: Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="CommDiagnostics.html">Module: CommDiagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Curl.html">Module: Curl</a><ul>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#dependencies">Dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#enabling-curl-support">Enabling Curl Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#using-curl-support-in-chapel">Using Curl Support in Chapel</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-1">Example 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-2">Example 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-3">Example 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-4">Example 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-5">Example 5</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-6">Example 6</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#example-7">Example 7</a></li>
<li class="toctree-l2"><a class="reference internal" href="Curl.html#curl-support-types-and-functions">Curl Support Types and Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Error.html">Module: Error</a></li>
<li class="toctree-l1"><a class="reference internal" href="FFTW.html">Module: FFTW</a></li>
<li class="toctree-l1"><a class="reference internal" href="FFTW_MT.html">Module: FFTW_MT</a></li>
<li class="toctree-l1"><a class="reference internal" href="FileSystem.html">Module: FileSystem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="FileSystem.html#file-directory-manipulations">File/Directory Manipulations</a></li>
<li class="toctree-l2"><a class="reference internal" href="FileSystem.html#file-directory-properties">File/Directory Properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="FileSystem.html#locale-state-functionality">Locale State Functionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="FileSystem.html#file-system-traversal-iterators">File System Traversal Iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="FileSystem.html#constant-and-function-definitions">Constant and Function Definitions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="GMP.html">Module: GMP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="GMP.html#using-the-gmp-module">Using the GMP Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="GMP.html#using-the-bigint-class">Using the BigInt class</a></li>
<li class="toctree-l2"><a class="reference internal" href="GMP.html#calling-gmp-functions-directly">Calling GMP functions directly</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Module: HDFS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#dependencies">Dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="#enabling-hdfs-support">Enabling HDFS Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-hdfs-support-in-chapel">Using HDFS Support in Chapel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#setting-up-hadoop">Setting up Hadoop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hdfs-support-types-and-functions">HDFS Support Types and Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="HDFSiterator.html">Module: HDFSiterator</a></li>
<li class="toctree-l1"><a class="reference internal" href="Help.html">Module: Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="IO.html">Module: IO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="IO.html#i-o-overview">I/O Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#design-rationale">Design Rationale</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#i-o-styles">I/O Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#files">Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#functions-for-channel-creation">Functions for Channel Creation</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#synchronization-of-channel-data-and-avoiding-data-races">Synchronization of Channel Data and Avoiding Data Races</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#performing-i-o-with-channels">Performing I/O with Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#functions-for-closing-channels">Functions for Closing Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#the-stdin-stdout-and-stderr-channels">The <tt class="docutils literal"><span class="pre">stdin</span></tt>, <tt class="docutils literal"><span class="pre">stdout</span></tt>, and <tt class="docutils literal"><span class="pre">stderr</span></tt> Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#error-handling">Error Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#ensuring-successful-i-o">Ensuring Successful I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#correspondence-to-c-i-o">Correspondence to C I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#bytes-type">Bytes Type</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#buffers">Buffers</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#formatted-i-o">Formatted I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO.html#io-functions-and-types">IO Functions and Types</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="List.html">Module: List</a></li>
<li class="toctree-l1"><a class="reference internal" href="Math.html">Module: Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="Memory.html">Module: Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="Norm.html">Module: Norm</a></li>
<li class="toctree-l1"><a class="reference internal" href="Path.html">Module: Path</a></li>
<li class="toctree-l1"><a class="reference internal" href="Random.html">Module: Random</a></li>
<li class="toctree-l1"><a class="reference internal" href="RecordParser.html">Module: RecordParser</a><ul>
<li class="toctree-l2"><a class="reference internal" href="RecordParser.html#example-1">Example 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="RecordParser.html#example-2">Example 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="RecordParser.html#recordparser-types-and-functions">RecordParser Types and Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Regexp.html">Module: Regexp</a><ul>
<li class="toctree-l2"><a class="reference internal" href="Regexp.html#enabling-regular-expression-support">Enabling Regular Expression Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="Regexp.html#using-regular-expression-support">Using Regular Expression Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="Regexp.html#re2-regular-expression-syntax-reference">RE2 regular expression syntax reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="Regexp.html#regular-expression-types-and-methods">Regular Expression Types and Methods</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Search.html">Module: Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sort.html">Module: Sort</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sys.html">Module: Sys</a></li>
<li class="toctree-l1"><a class="reference internal" href="SysBasic.html">Module: SysBasic</a></li>
<li class="toctree-l1"><a class="reference internal" href="Time.html">Module: Time</a></li>
<li class="toctree-l1"><a class="reference internal" href="Types.html">Module: Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="UtilMath.html">Module: UtilMath</a></li>
<li class="toctree-l1"><a class="reference internal" href="UtilReplicatedVar.html">Module: UtilReplicatedVar</a><ul>
<li class="toctree-l2"><a class="reference internal" href="UtilReplicatedVar.html#how-to-use-replicated-variables">How to use replicated variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="UtilReplicatedVar.html#replicating-over-a-subset-of-locales">Replicating over a subset of locales</a></li>
<li class="toctree-l2"><a class="reference internal" href="UtilReplicatedVar.html#declarations">Declarations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gen/doc/SysCTypes.html">Module: SysCTypes</a></li>
<li class="toctree-l1"><a class="reference internal" href="startInitCommDiags.html">Module: startInitCommDiags</a></li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">chpldoc</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
    <li>Module: HDFS</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="../../_sources/modules/standard/HDFS.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <span class="target" id="module-HDFS"></span><div class="section" id="module-hdfs">
<h1>Module: HDFS<a class="headerlink" href="#module-hdfs" title="Permalink to this headline">¶</a></h1>
<p>Support for Hadoop Distributed Filesystem</p>
<p>This module implements support for the
<a class="reference external" href="http://hadoop.apache.org/">Hadoop</a>
<a class="reference external" href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">Distributed Filesystem</a> (HDFS).</p>
<div class="section" id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h2>
<p>The HDFS functionality in Chapel is dependent upon both Hadoop and Java being
installed.  Your <tt class="docutils literal"><span class="pre">HADOOP_INSTALL</span></tt>, <tt class="docutils literal"><span class="pre">JAVA_INSTALL</span></tt> and <tt class="docutils literal"><span class="pre">CLASSPATH</span></tt>
environment variables must be set as described below in
<a class="reference internal" href="#setting-up-hadoop"><em>Setting up Hadoop</em></a>.  Without this it will not compile with HDFS, even if
the flags are set. As well, the HDFS functionality is also dependent upon the
<tt class="docutils literal"><span class="pre">CHPL_AUXIO_INCLUDE</span></tt> and <tt class="docutils literal"><span class="pre">CHPL_AUXIO_LIBS</span></tt> environment variables being set
properly. For more information on how to set these properly, see
doc/technotes/README.auxIO in a Chapel release.</p>
</div>
<div class="section" id="enabling-hdfs-support">
<h2>Enabling HDFS Support<a class="headerlink" href="#enabling-hdfs-support" title="Permalink to this headline">¶</a></h2>
<p>Once you have ensured that Hadoop and Java are installed and have the
five variables above, defined, set the environment variable
CHPL_AUX_FILESYS to &#8216;hdfs&#8217; to enable HDFS support:</p>
<div class="highlight-sh"><div class="highlight"><pre><span class="nb">export </span><span class="nv">CHPL_AUX_FILESYS</span><span class="o">=</span>hdfs
</pre></div>
</div>
<p>Then, rebuild Chapel by executing &#8216;make&#8217; from $CHPL_HOME.</p>
<div class="highlight-sh"><div class="highlight"><pre>make
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If HDFS support is not enabled (which is the default), all
features described below will compile successfully but will result in
an error at runtime such as: &#8220;No HDFS Support&#8221;.</p>
</div>
</div>
<div class="section" id="using-hdfs-support-in-chapel">
<h2>Using HDFS Support in Chapel<a class="headerlink" href="#using-hdfs-support-in-chapel" title="Permalink to this headline">¶</a></h2>
<p>There are three ways provided to open HDFS files within Chapel.</p>
<div class="section" id="using-an-hdfs-filesystem-with-open-url-hdfs">
<h3>Using an HDFS filesystem with open(url=&#8221;hdfs://...&#8221;)<a class="headerlink" href="#using-an-hdfs-filesystem-with-open-url-hdfs" title="Permalink to this headline">¶</a></h3>
<div class="highlight-chapel"><div class="highlight"><pre><span class="c1">// Open a file on HDFS connecting to the default HDFS instance</span>
<span class="kd">var</span> <span class="nx">f</span> <span class="o">=</span> <span class="nx">open</span><span class="p">(</span><span class="nx">mode</span><span class="o">=</span><span class="nx">iomode</span><span class="p">.</span><span class="nx">r</span><span class="p">,</span> <span class="nx">url</span><span class="o">=</span><span class="s">&quot;hdfs://host:port/path&quot;</span><span class="p">);</span>

<span class="c1">// Open up a reader and read from the file</span>
<span class="kd">var</span> <span class="nx">reader</span> <span class="o">=</span> <span class="nx">f</span><span class="p">.</span><span class="nx">reader</span><span class="p">();</span>

<span class="c1">// ...</span>

<span class="nx">reader</span><span class="p">.</span><span class="nx">close</span><span class="p">();</span>

<span class="nx">f</span><span class="p">.</span><span class="nx">close</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="section" id="explicitly-using-replicated-hdfs-connections-and-files">
<h3>Explicitly Using Replicated HDFS Connections and Files<a class="headerlink" href="#explicitly-using-replicated-hdfs-connections-and-files" title="Permalink to this headline">¶</a></h3>
<div class="highlight-chapel"><div class="highlight"><pre><span class="k">use</span> <span class="nx">HDFS</span><span class="p">;</span>

<span class="c1">// Connect to HDFS via the default username (or whichever you want)</span>
<span class="c1">//</span>
<span class="kd">var</span> <span class="nx">hdfs</span> <span class="o">=</span> <span class="nx">hdfsChapelConnect</span><span class="p">(</span><span class="s">&quot;default&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>

<span class="c1">//</span>
<span class="c1">// Create a file per locale</span>
<span class="c1">//</span>
<span class="kd">var</span> <span class="nx">gfl</span>  <span class="o">=</span> <span class="nx">hdfs</span><span class="p">.</span><span class="nx">hdfsOpen</span><span class="p">(</span><span class="s">&quot;/user/johnDoe/isThisAfile.txt&quot;</span><span class="p">,</span> <span class="nx">iomode</span><span class="p">.</span><span class="nx">r</span><span class="p">);</span>

<span class="o">..</span><span class="p">.</span>
<span class="c1">//</span>
<span class="c1">// On any given locale, you can get the local file for the locale that</span>
<span class="c1">// the task is currently running on via:</span>
<span class="c1">//</span>
<span class="kd">var</span> <span class="nx">fl</span> <span class="o">=</span> <span class="nx">gfl</span><span class="p">.</span><span class="nx">getLocal</span><span class="p">();</span>

<span class="c1">// This file can be used as with a traditional file in Chapel, by</span>
<span class="c1">// creating reader channels on it.</span>

<span class="c1">// When you are done and want to close the files and disconnect from</span>
<span class="c1">// HDFS, use:</span>

<span class="nx">gfl</span><span class="p">.</span><span class="nx">hdfsClose</span><span class="p">();</span>
<span class="nx">hdfs</span><span class="p">.</span><span class="nx">hdfsChapelDisconnect</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="section" id="explicitly-using-local-hdfs-connections-and-files">
<h3>Explicitly Using Local HDFS Connections and Files<a class="headerlink" href="#explicitly-using-local-hdfs-connections-and-files" title="Permalink to this headline">¶</a></h3>
<p>The HDFS module file also supports non-replicated values across
locales. So if you only wanted to connect to HDFS and open a file on
locale 1 you could do:</p>
<div class="highlight-chapel"><div class="highlight"><pre><span class="k">on</span> <span class="nx">Locales</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">hdfs</span> <span class="o">=</span> <span class="nx">hdfs_chapel_connect</span><span class="p">(</span><span class="s">&quot;default&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="kd">var</span> <span class="nx">fl</span> <span class="o">=</span> <span class="nx">hdfs</span><span class="p">.</span><span class="nx">hdfs_chapel_open</span><span class="p">(</span><span class="s">&quot;/user/johnDoe/myFile.txt&quot;</span><span class="p">,</span> <span class="nx">iomode</span><span class="p">.</span><span class="nx">cw</span><span class="p">);</span>
  <span class="o">..</span><span class="p">.</span>
  <span class="kd">var</span> <span class="nx">read</span> <span class="o">=</span> <span class="nx">fl</span><span class="p">.</span><span class="nx">reader</span><span class="p">();</span>
  <span class="o">..</span><span class="p">.</span>
  <span class="nx">fl</span><span class="p">.</span><span class="nx">close</span><span class="p">();</span>
  <span class="nx">hdfs</span><span class="p">.</span><span class="nx">hdfs_chapel_disconnect</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The only stipulations are that you cannot open a file in both read and
write mode at the same time. (i.e iomode.r and iomode.cw are the only
modes that are supported, due to HDFS limitations).</p>
</div>
</div>
<div class="section" id="setting-up-hadoop">
<span id="id1"></span><h2>Setting up Hadoop<a class="headerlink" href="#setting-up-hadoop" title="Permalink to this headline">¶</a></h2>
<p>If you have a working installation of Hadoop already, you can skip
this section, other than to set up your CLASSPATH environment
variable.  This section is written so that people without sudo
permission can install and use HDFS.  If you do have sudo permissions,
you can usually install all of these via a package manager.</p>
<p>The general outline for these instructions is:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Install and point to the jdk to provide code Chapel needs to
compile against libhdfs (<a class="reference internal" href="#setup-hadoop-1"><em>Step 1</em></a>)</li>
<li>Install Hadoop (<a class="reference internal" href="#setup-hadoop-2"><em>Step 2</em></a>)</li>
<li>Set up Hadoop on (a) the local host or (b) a cluster of hosts
(<a class="reference internal" href="#setup-hadoop-3"><em>Step 3</em></a>)</li>
<li>Start up HDFS (<a class="reference internal" href="#setup-hadoop-4"><em>Step 4</em></a>)</li>
<li>Stop HDFS when you&#8217;re done (<a class="reference internal" href="#setup-hadoop-5"><em>Step 5</em></a>)</li>
<li>Set up Chapel to run in distributed mode (<a class="reference internal" href="#setup-hadoop-6"><em>Step 6</em></a>)</li>
</ol>
</div></blockquote>
<p>First reflect your directory structure and version numbers (etc) in the
<a class="reference internal" href="#setup-hadoop-bashrc"><em>sample .bashrc</em></a> and put it in your .bashrc (or
.bash_profile &#8211; your choice) and source whichever one you put it into.</p>
<ol class="arabic simple" id="setup-hadoop-1">
<li>Make sure you have a SERVER edition of the jdk installed and
point JAVA_INSTALL to it (see the same .bashrc below)</li>
</ol>
<ol class="arabic" id="setup-hadoop-2" start="2">
<li><p class="first">Install Hadoop</p>
<ul>
<li><p class="first">Download the latest version of Hadoop and unpack it</p>
</li>
<li><p class="first">Now in the unpacked directory, open conf/hadoop-env.sh and edit:</p>
<ul>
<li><p class="first">set <tt class="docutils literal"><span class="pre">JAVA_INSTALL</span></tt> to be the part before <tt class="docutils literal"><span class="pre">bin/</span></tt>... when you do:</p>
<blockquote>
<div><div class="highlight-sh"><div class="highlight"><pre>which java
</pre></div>
</div>
</div></blockquote>
</li>
<li><p class="first">set <tt class="docutils literal"><span class="pre">HADOOP_CLASSPATH=$HADOOP_HOME/&quot;&quot;*:$HADOOP_HOME/lib/&quot;&quot;*:</span></tt></p>
</li>
</ul>
</li>
<li><p class="first">Now in conf/hdfs-site.xml put the replication number that you
want for the field <tt class="docutils literal"><span class="pre">dfs.replication</span></tt> (this will set the
replication of blocks of the files in HDFS)</p>
</li>
<li><p class="first">Now set up passwordless ssh, if you haven&#8217;t yet:</p>
<div class="highlight-sh"><div class="highlight"><pre>ssh-keygen -t dsa -P <span class="s1">&#39;&#39;</span> -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
<ol class="arabic" id="setup-hadoop-3" start="3">
<li><p class="first">Set up Hadoop</p>
<ol class="loweralpha">
<li><p class="first">For the local host - See the
<a class="reference external" href="http://hadoop.apache.org/docs/stable/single_node_setup.html">Hadoop website</a>
for good documentation on how to do this.</p>
</li>
<li><p class="first">For a cluster of hosts. If you want to run Hadoop over a cluster, there
are good tutorials online. Although it is usually as easy as making
edits to the following files in <tt class="docutils literal"><span class="pre">$HADOOP_HOME/conf</span></tt>:</p>
<ul>
<li><p class="first">adding the name of the nodes to <tt class="docutils literal"><span class="pre">slaves</span></tt></p>
</li>
<li><p class="first">putting what you want to be the namenode in <tt class="docutils literal"><span class="pre">masters</span></tt></p>
</li>
<li><p class="first">putting the master node in <tt class="docutils literal"><span class="pre">core-site.xml</span></tt> and <tt class="docutils literal"><span class="pre">mapred-site.xml</span></tt></p>
</li>
<li><p class="first">running:</p>
<div class="highlight-sh"><div class="highlight"><pre>hadoop-daemon.sh start datanode
hadoop-daemon.sh start tasktracker
</pre></div>
</div>
</li>
</ul>
<p>After this go to your datanode site and you should see a new
datanode.</p>
<p>A good online tutorial for this as well can be found here:
<a class="reference external" href="http://hadoop.apache.org/docs/stable/cluster_setup.html">http://hadoop.apache.org/docs/stable/cluster_setup.html</a></p>
</li>
</ol>
</li>
</ol>
<ol class="arabic" id="setup-hadoop-4" start="4">
<li><p class="first">Start HDFS</p>
<ul>
<li><p class="first">Now all we need to do is format the namenode and start things up:</p>
<div class="highlight-sh"><div class="highlight"><pre>hadoop namenode -format
start-all.sh  <span class="c"># (This will start hdfs and the tasktracker/jobtracker)</span>
</pre></div>
</div>
</li>
<li><p class="first">In general, hadoop has the same type of commands as bash,
usually in the form:</p>
<div class="highlight-sh"><div class="highlight"><pre>hadoop dfs -&lt;<span class="nb">command</span>&gt; &lt;regular args to that <span class="nb">command</span>&gt;
</pre></div>
</div>
</li>
<li><p class="first">At this point, you can compile and run Chapel programs using HDFS</p>
</li>
<li><p class="first">You can check the status of Hadoop via http, for example on a local
host (e.g., for <a class="reference internal" href="#setup-hadoop-3"><em>3a above</em></a>), using:</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="http://localhost:50070/">http://localhost:50070/</a></li>
<li><a class="reference external" href="http://localhost:50030/">http://localhost:50030/</a></li>
</ul>
</div></blockquote>
<p>For cluster mode (<a class="reference internal" href="#setup-hadoop-3"><em>3b</em></a>), you&#8217;ll use the name of the
master host in the URL and its port (see the web for details).</p>
</li>
</ul>
</li>
</ol>
<ol class="arabic" id="setup-hadoop-5" start="5">
<li><p class="first">Shut things down:</p>
<div class="highlight-sh"><div class="highlight"><pre>stop-all.sh   <span class="c"># (This will stop hdfs and mapreduce)</span>
</pre></div>
</div>
</li>
</ol>
<ol class="arabic simple" id="setup-hadoop-6" start="6">
<li>Set up Chapel to run in distributed mode:<ul>
<li>You&#8217;ll need to set up your Chapel environment to target multiple
locales in the standard way (see README.multilocale and the
&#8220;Settings to run Chapel on multiple nodes&#8221; section of the
.bashrc below).</li>
<li>After this you should be able to run Chapel code with HDFS over
a cluster of computers the same way as you normally would.</li>
</ul>
</li>
</ol>
<p id="setup-hadoop-bashrc">Here is a sample .bashrc for using Hadoop within Chapel:</p>
<div class="highlight-sh"><div class="highlight"><pre><span class="c">#</span>
<span class="c"># For Hadoop</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">HADOOP_INSTALL</span><span class="o">=</span>&lt;Place where you have Hadoop installed&gt;
<span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span><span class="nv">$HADOOP_INSTALL</span>
<span class="nb">export </span><span class="nv">HADOOP_VERSION</span><span class="o">=</span>&lt;Your Hadoop version number&gt;
<span class="c">#</span>
<span class="c"># Note that the following environment variables might contain more paths than</span>
<span class="c"># those listed below if you have more than one IO system enabled. These are all</span>
<span class="c"># that you will need in order to use HDFS (only)</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">CHPL_AUXIO_INCLUDE</span><span class="o">=</span><span class="s2">&quot;-I</span><span class="nv">$JAVA_INSTALL</span><span class="s2">/include -I</span><span class="nv">$JAVA_INSTALL</span><span class="s2">/include/linux  -I</span><span class="nv">$HADOOP_INSTALL</span><span class="s2">/src/c++/libhdfs&quot;</span>
<span class="nb">export </span><span class="nv">CHPL_AUXIO_LIBS</span><span class="o">=</span><span class="s2">&quot;-L</span><span class="nv">$JAVA_INSTALL</span><span class="s2">/jre/lib/amd64/server -L</span><span class="nv">$HADOOP_INSTALL</span><span class="s2">/c++/Linux-amd64-64/lib&quot;</span>

<span class="c">#</span>
<span class="c"># So we can run things such as start-all.sh etc. from anywhere and</span>
<span class="c"># don&#39;t need to be in $HADOOP_INSTALL</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_INSTALL</span>/bin

<span class="c">#</span>
<span class="c"># Point to the JDK installation</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">JAVA_INSTALL</span><span class="o">=</span>&lt;Place where you have the jdk installed&gt;

<span class="c">#</span>
<span class="c"># Add Hadoop directories to the Java class path</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">CLASSPATH</span><span class="o">=</span><span class="nv">$CLASSPATH</span>:<span class="nv">$HADOOP_HOME</span>/<span class="s2">&quot;&quot;</span>*:<span class="nv">$HADOOP_HOME</span>/lib/<span class="s2">&quot;&quot;</span>*:<span class="nv">$HADOOP_HOME</span>/conf/<span class="s2">&quot;&quot;</span>*:<span class="k">$(</span>hadoop classpath<span class="k">)</span>:

<span class="c">#</span>
<span class="c"># So we don&#39;t have to &quot;install&quot; these things</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:<span class="nv">$HADOOP_HOME</span>/c++/Linux-amd64-64/lib:<span class="nv">$HADOOP_HOME</span>/src/c++/libhdfs:<span class="nv">$JAVA_INSTALL</span>/jre/lib/amd64/server:<span class="nv">$JAVA_INSTALL</span>:<span class="nv">$HADOOP_HOME</span>/lib:<span class="nv">$JAVA_INSTALL</span>/jre/lib/amd64:<span class="nv">$CLASSPATH</span>

<span class="c">#</span>
<span class="c"># Settings to run Chapel on multiple nodes</span>
<span class="c">#</span>
<span class="nb">export </span><span class="nv">GASNET_SPAWNFN</span><span class="o">=</span>S
<span class="nb">export </span><span class="nv">SSH_SERVERS</span><span class="o">=</span>&lt;the names of the computers in your cluster&gt;
<span class="nb">export </span><span class="nv">SSH_CMD</span><span class="o">=</span>ssh
<span class="nb">export </span><span class="nv">SSH_OPTIONS</span><span class="o">=</span>-x
<span class="nb">export </span><span class="nv">GASNET_ROUTE_OUTPUT</span><span class="o">=</span>0
</pre></div>
</div>
</div>
<div class="section" id="hdfs-support-types-and-functions">
<h2>HDFS Support Types and Functions<a class="headerlink" href="#hdfs-support-types-and-functions" title="Permalink to this headline">¶</a></h2>
<dl class="record">
<dt id="HDFS.hdfsChapelFile">
<em class="property">record </em><tt class="descname">hdfsChapelFile</tt><a class="headerlink" href="#HDFS.hdfsChapelFile" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds a file per locale</p>
</dd></dl>

<dl class="record">
<dt id="HDFS.hdfsChapelFileSystem">
<em class="property">record </em><tt class="descname">hdfsChapelFileSystem</tt><a class="headerlink" href="#HDFS.hdfsChapelFileSystem" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds a connection to HDFS per locale</p>
</dd></dl>

<dl class="function">
<dt id="HDFS.hdfsChapelConnect">
<em class="property">proc </em><tt class="descname">hdfsChapelConnect</tt><big>(</big><em>out error: syserr</em>, <em>path: c_string</em>, <em>port: int</em><big>)</big>: c_void_ptr<a class="headerlink" href="#HDFS.hdfsChapelConnect" title="Permalink to this definition">¶</a></dt>
<dd><p>Make a connection to HDFS for a single locale</p>
</dd></dl>

<dl class="function">
<dt>
<em class="property">proc </em><tt class="descname">hdfsChapelConnect</tt><big>(</big><em>path: string</em>, <em>port: int</em><big>)</big>: hdfsChapelFileSystem</dt>
<dd><p>Connect to HDFS and create a filesystem ptr per locale</p>
</dd></dl>

<dl class="method">
<dt id="HDFS.hdfsChapelFileSystem.hdfsChapelDisconnect">
<em class="property">proc </em><tt class="descclassname">hdfsChapelFileSystem.</tt><tt class="descname">hdfsChapelDisconnect</tt><big>(</big><big>)</big><a class="headerlink" href="#HDFS.hdfsChapelFileSystem.hdfsChapelDisconnect" title="Permalink to this definition">¶</a></dt>
<dd><p>Diconnect from the configured HDFS filesystem on each locale</p>
</dd></dl>

<dl class="method">
<dt id="HDFS.hdfsChapelFileSystem.hdfsOpen">
<em class="property">proc </em><tt class="descclassname">hdfsChapelFileSystem.</tt><tt class="descname">hdfsOpen</tt><big>(</big><em>path: string</em>, <em>mode: iomode</em>, <em>hints: iohints = IOHINT_NONE</em>, <em>style: iostyle = defaultIOStyle()</em><big>)</big>: hdfsChapelFile<a class="headerlink" href="#HDFS.hdfsChapelFileSystem.hdfsOpen" title="Permalink to this definition">¶</a></dt>
<dd><p>Open a file on each locale</p>
</dd></dl>

<dl class="method">
<dt id="HDFS.hdfsChapelFile.hdfsClose">
<em class="property">proc </em><tt class="descclassname">hdfsChapelFile.</tt><tt class="descname">hdfsClose</tt><big>(</big><big>)</big><a class="headerlink" href="#HDFS.hdfsChapelFile.hdfsClose" title="Permalink to this definition">¶</a></dt>
<dd><p>Close a file opened with <a class="reference internal" href="#HDFS.hdfsChapelFileSystem.hdfsOpen" title="HDFS.hdfsChapelFileSystem.hdfsOpen"><tt class="xref chpl chpl-proc docutils literal"><span class="pre">hdfsChapelFileSystem.hdfsOpen</span></tt></a></p>
</dd></dl>

<dl class="method">
<dt id="HDFS.hdfsChapelFileSystem_local.hdfs_chapel_open">
<em class="property">proc </em><tt class="descclassname">hdfsChapelFileSystem_local.</tt><tt class="descname">hdfs_chapel_open</tt><big>(</big><em>path: string</em>, <em>mode: iomode</em>, <em>hints: iohints = IOHINT_NONE</em>, <em>style: iostyle = defaultIOStyle()</em><big>)</big>: file<a class="headerlink" href="#HDFS.hdfsChapelFileSystem_local.hdfs_chapel_open" title="Permalink to this definition">¶</a></dt>
<dd><p>Open a file on an HDFS filesystem for a single locale</p>
</dd></dl>

<dl class="function">
<dt id="HDFS.hdfs_chapel_connect">
<em class="property">proc </em><tt class="descname">hdfs_chapel_connect</tt><big>(</big><em>path: string</em>, <em>port: int</em><big>)</big>: hdfsChapelFileSystem_local<a class="headerlink" href="#HDFS.hdfs_chapel_connect" title="Permalink to this definition">¶</a></dt>
<dd><p>Connect to an HDFS filesystem on a single locale</p>
</dd></dl>

</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="HDFSiterator.html" class="btn btn-neutral float-right" title="Module: HDFSiterator">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="GMP.html" class="btn btn-neutral" title="Module: GMP"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Cray Inc.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 

</body>
</html>
