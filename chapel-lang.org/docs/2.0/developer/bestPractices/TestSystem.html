<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Chapel Testing System &mdash; Chapel Documentation 2.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/style.css" />

  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="chplspell" href="SpellChecking.html" />
    <link rel="prev" title="The CHPL_DEVELOPER environment variable" href="CHPL_DEVELOPER.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

<a href="../../index.html" class="icon icon-home"> Chapel Documentation

<!-- display version if button won't be rendered -->
<?php if (false) { ?>
<br>2.0
<?php } ?>

</a>

<?php
// Variables given by sphinx
$chplTitle = "2.0";
$pagename = "developer/bestPractices/TestSystem";
include "../..//versionButton.php";
?>


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
  
              <p class="caption" role="heading"><span class="caption-text">Compiling and Running Chapel</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../usingchapel/QUICKSTART.html">Quickstart Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usingchapel/index.html">Using Chapel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../platforms/index.html">Platform-Specific Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../technotes/index.html">Technical Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/index.html">Tools</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Docs for Contributors</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Best Practices for Contributors</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="GettingStarted.html">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="ContributorInfo.html">Contributor Info</a></li>
<li class="toctree-l3"><a class="reference internal" href="DCO.html">Getting started with Chapel and the Developer Certificate of Origin (DCO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="CompilerDebugging.html">Tips On Debugging The Compiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="CompilerIRTricks.html">Examining/Debugging Compiler IR</a></li>
<li class="toctree-l3"><a class="reference internal" href="ErrorWarningMessaging.html">How To Generate Warnings And Error Messages</a></li>
<li class="toctree-l3"><a class="reference internal" href="RuntimeLibrary.html">The Chapel Runtime Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="GeneratedCode.html">All About Compiler-Generated Code</a></li>
<li class="toctree-l3"><a class="reference internal" href="GASNetOnDesktops.html">Running Chapel Programs with GASNet on your Desktop</a></li>
<li class="toctree-l3"><a class="reference internal" href="git.html">Git tips for Chapel developers</a></li>
<li class="toctree-l3"><a class="reference internal" href="CHPL_DEVELOPER.html">The CHPL_DEVELOPER environment variable</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Chapel Testing System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#outline">Outline</a></li>
<li class="toctree-l4"><a class="reference internal" href="#how-to-make">How to Make</a></li>
<li class="toctree-l4"><a class="reference internal" href="#invoking-start-test">Invoking start_test</a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary-of-testing-files">Summary of Testing Files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="SpellChecking.html">chplspell</a></li>
<li class="toctree-l3"><a class="reference internal" href="Valgrind.html">Valgrind</a></li>
<li class="toctree-l3"><a class="reference internal" href="Sanitizers.html">Sanitizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="Deprecation.html">Chapel’s Deprecation Policy</a></li>
<li class="toctree-l3"><a class="reference internal" href="Unstable.html">Unstable Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="NightlyTesting.html">Nightly Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="StandardModuleStyle.html">Standard Module Style</a></li>
<li class="toctree-l3"><a class="reference internal" href="TestAnnotationsLocally.html">How to test ANNOTATIONS.yaml changes locally</a></li>
<li class="toctree-l3"><a class="reference internal" href="buildingdocs.html">Building Chapel Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="Potpourri.html">Miscellaneous Notes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../compiler-internals/index.html">Frontend Library API Docs</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Writing Chapel Programs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../language/reference.html">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Hello World Variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../primers/index.html">Primers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../language/spec/index.html">Language Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/standard.html">Standard Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/packages.html">Package Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/layoutdist.html">Standard Layouts and Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mason-packages/index.html">Mason Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../users-guide/index.html">Chapel Users Guide (WIP)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language History</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../language/evolution.html">Chapel Evolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../language/archivedSpecs.html">Documentation Archives</a></li>
</ul>

  <p class="caption" role="heading"><span class="caption-text">Indexes</span></p>
  <ul>
    <li class="toctree-11"><a class="reference internal" href="../../chpl-modindex.html">Chapel Module Index</a></li>
    <li class="toctree-11"><a class="reference internal" href="../../genindex.html">Complete Docs Index</a></li>
  </ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Chapel Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Docs for Contributors</a></li>
          <li class="breadcrumb-item"><a href="index.html">Best Practices for Contributors</a></li>
      <li class="breadcrumb-item active">Chapel Testing System</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/developer/bestPractices/TestSystem.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="chapel-testing-system">
<span id="readme-testsystem"></span><h1>Chapel Testing System<a class="headerlink" href="#chapel-testing-system" title="Permalink to this heading">¶</a></h1>
<p>The Chapel testing system is a key piece of technology for the Chapel
developer.  We use it as a harness for doing test-driven development,
for performing sanity checks on code before committing it, for bug and
issue tracking, and for nightly correctness and performance regression
testing.  Getting really comfortable with it is one of the most
important things a developer can do early in the development cycle.</p>
<p>The tests for the testing system are located in <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/test</span></code>.
The main script that drives the test system itself is
<code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/util/start_test</span></code>, though it relies on several helper scripts
located in <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/util/test</span></code>.</p>
<p>This document provides only a high-level introduction to the testing
system.  For further details, ask a core Chapel developer for
suggestions.  You can also get a sense for the test system by looking
through the test directory itself to see how it is used in practice.</p>
<section id="outline">
<h2>Outline<a class="headerlink" href="#outline" title="Permalink to this heading">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="#how-to-make">How to Make</a></p>
<ul>
<li><p><a class="reference internal" href="#a-correctness-test">A Correctness Test</a></p>
<ul>
<li><p><a class="reference internal" href="#outside-arguments-or-settings">With Outside Arguments</a></p>
<ul>
<li><p><a class="reference internal" href="#compile-time-arguments">Compile-time Arguments</a></p></li>
<li><p><a class="reference internal" href="#execution-time-arguments">Execution-time Arguments</a></p></li>
<li><p><a class="reference internal" href="#environment-variables">Environment Variables</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#controlling-how-it-runs">Controlling How It Runs</a></p>
<ul>
<li><p><a class="reference internal" href="#running-multiple-times">Running Multiple Times</a></p></li>
<li><p><a class="reference internal" href="#limiting-time-taken">Limiting Time Taken</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tests-with-varying-output">With Varying Output</a></p>
<ul>
<li><p><a class="reference internal" href="#limiting-where-the-test-runs">Test Not Applicable In All Settings</a></p></li>
<li><p><a class="reference internal" href="#testing-different-behavior-in-different-settings">Testing Different Behavior in Different Settings</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#using-precomp-preexec-and-prediff-files">Using precomp, preexec, and prediff files</a></p></li>
<li><p><a class="reference internal" href="#using-pretest">Using PRETEST</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#a-performance-test">A Performance Test</a></p>
<ul>
<li><p><a class="reference internal" href="#identifying-performance-keys">Identifying Performance Keys</a></p></li>
<li><p><a class="reference internal" href="#validating-performance-test-output">Validating Performance Test Output</a></p></li>
<li><p><a class="reference internal" href="#accumulating-performance-data-in-dat-files">Accumulating Performance Data in .dat files</a></p></li>
<li><p><a class="reference internal" href="#other-performance-testing-options">Other Performance Testing Options</a></p></li>
<li><p><a class="reference internal" href="#comparing-multiple-versions">Comparing Multiple Versions</a></p>
<ul>
<li><p><a class="reference internal" href="#comparing-to-a-c-version">Comparing to a C version</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#creating-a-graph-comparing-multiple-variations">Creating a graph comparing multiple variations</a></p></li>
<li><p><a class="reference internal" href="#multilocale-performance-testing">Multilocale Performance Testing</a></p></li>
<li><p><a class="reference internal" href="#multilocale-communication-counts-testing">Multilocale Communication Counts Testing</a></p></li>
<li><p><a class="reference internal" href="#test-your-test-before-submitting">Test Your Test Before Submitting</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#a-test-that-tracks-a-failure">A Test That Tracks A Failure</a></p>
<ul>
<li><p><a class="reference internal" href="#github-issues">Github Issues</a></p></li>
<li><p><a class="reference internal" href="#tracking-current-failure-mode">Tracking Current Failure Mode</a></p></li>
<li><p><a class="reference internal" href="#resolving-a-future">Resolving a Future</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#invoking-start-test">Invoking start_test</a></p>
<ul>
<li><p><a class="reference internal" href="#correctness-testing">Correctness Testing</a></p>
<ul>
<li><p><a class="reference internal" href="#parallel-testing">Parallel Testing</a></p></li>
<li><p><a class="reference internal" href="#gpu-testing">GPU Testing</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#performance-testing">Performance Testing</a></p></li>
<li><p><a class="reference internal" href="#sample-output">Sample Output</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#summary-of-testing-files">Summary of Testing Files</a></p></li>
</ul>
</div></blockquote>
</section>
<section id="how-to-make">
<h2>How to Make<a class="headerlink" href="#how-to-make" title="Permalink to this heading">¶</a></h2>
<section id="a-correctness-test">
<h3>A Correctness Test<a class="headerlink" href="#a-correctness-test" title="Permalink to this heading">¶</a></h3>
<p>Though trivial, this test is available at <a class="reference external" href="https://github.com/chapel-lang/chapel/pull/295/commits/8c0aaf04dabc007e061588876082f5a1f95c0cae">$CHPL_HOME/test/Samples/Correctness</a>
in the Chapel source repository</p>
<p>A simplest use of the test system is to create a <code class="docutils literal notranslate"><span class="pre">.chpl</span></code> file containing
some Chapel code and a <code class="docutils literal notranslate"><span class="pre">.good</span></code> file containing the expected output.  For
example, given a directory containing two files:</p>
<p><code class="docutils literal notranslate"><span class="pre">hi.chpl</span></code></p>
<blockquote>
<div><div class="highlight-chapel notranslate"><div class="highlight"><pre><span></span><span class="nx">writeln</span><span class="p">(</span><span class="s">&quot;Hi!&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">hi.good</span></code></p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Hi!
</pre></div>
</div>
</div></blockquote>
<p>The test system can be exercised by invoking:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">hi.chpl</span></code></p>
</div></blockquote>
<p>This is assuming <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/util/</span></code> is in the user’s <cite>$PATH</cite>, which is
taken care of when sourcing <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/util/setchplenv.bash</span></code>.</p>
<p>This will cause the compiler to compile hi.chpl.  If compiling hi.chpl does not
cause a compilation failure, start_test will then execute the resulting binary.
The concatenation of the compiler and executable output will then be compared
against the <code class="docutils literal notranslate"><span class="pre">.good</span></code> file.  A transcript of the test system’s actions is
printed to the console and also stored in <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/test/Logs/</span></code> by default.</p>
<p>For more information on using <code class="docutils literal notranslate"><span class="pre">start_test</span></code>, see <a class="reference internal" href="#invoking-start-test">Invoking start_test</a>.</p>
<section id="outside-arguments-or-settings">
<h4>Outside Arguments or Settings<a class="headerlink" href="#outside-arguments-or-settings" title="Permalink to this heading">¶</a></h4>
<p>In addition to the simplest form of test shown above, the test system supports a
number of additional options for creating more complex tests.</p>
<p>These options are all specified using files in the same directory as the test.
Some files apply to a directory as a whole while others will apply to a single
test by sharing the same base filename.  Those files which impact the entire
directory are named in upper case, e.g. <code class="docutils literal notranslate"><span class="pre">COMPOPTS</span></code>, or <code class="docutils literal notranslate"><span class="pre">PERFNUMTRIALS</span></code>.
They can be overridden or augmented with test-specific settings using the same
name but in lower case, e.g. <code class="docutils literal notranslate"><span class="pre">foo.compopts</span></code>.</p>
<section id="compile-time-arguments">
<h5>Compile-time Arguments<a class="headerlink" href="#compile-time-arguments" title="Permalink to this heading">¶</a></h5>
<p>To specify arguments to the compiler, provide a <code class="docutils literal notranslate"><span class="pre">COMPOPTS</span></code> or <code class="docutils literal notranslate"><span class="pre">.compopts</span></code>
file for the test.  All options for a single compilation should be on the same
line - specifying multiple lines will result in multiple compilations of the
test file.</p>
<p>For instance, to specify that the program should be compiled statically, this
file would be provided:</p>
<p><code class="docutils literal notranslate"><span class="pre">hi.compopts</span></code></p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--static
</pre></div>
</div>
</div></blockquote>
<p>To specify that the program should be compiled once statically and once
dynamically, the file would look like this:</p>
<p><code class="docutils literal notranslate"><span class="pre">hi.compopts</span></code></p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--static
--dynamic
</pre></div>
</div>
</div></blockquote>
<p>Note that sometimes different compilation arguments will result in different
output.  <a class="reference internal" href="#testing-different-behavior-in-different-settings">Testing Different Behavior in Different Settings</a> provides guidance
on how a test could respond to different behavior without modifying the output
that is generated.</p>
</section>
<section id="execution-time-arguments">
<h5>Execution-time Arguments<a class="headerlink" href="#execution-time-arguments" title="Permalink to this heading">¶</a></h5>
<p>Specification of arguments for execution time is performed similarly, using
a <code class="docutils literal notranslate"><span class="pre">EXECOPTS</span></code> or <code class="docutils literal notranslate"><span class="pre">.execopts</span></code> file.  Should both an <code class="docutils literal notranslate"><span class="pre">.execopts</span></code> and a
<code class="docutils literal notranslate"><span class="pre">.compopts</span></code> file be provided for a test, their options will be used in
combination.  For example, a test specified like this:</p>
<p><code class="docutils literal notranslate"><span class="pre">multiple-options.chpl</span></code></p>
<blockquote>
<div><div class="highlight-chapel notranslate"><div class="highlight"><pre><span></span><span class="kd">config</span> <span class="kd">var</span> <span class="nx">x</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>

<span class="k">if</span> <span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="k">then</span> <span class="nx">writeln</span><span class="p">(</span><span class="mi">5</span><span class="p">);</span> <span class="k">else</span> <span class="nx">writeln</span><span class="p">(</span><span class="mi">7</span><span class="p">);</span>
</pre></div>
</div>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">multiple-options.compopts</span></code></p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--static
--dynamic
</pre></div>
</div>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">multiple-options.execopts</span></code></p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--x<span class="o">=</span><span class="nb">true</span>
--x<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</div></blockquote>
<p>will be compiled twice, and executed four times by <code class="docutils literal notranslate"><span class="pre">start_test</span></code>:</p>
<ul>
<li><p>Compilation 1:</p>
<p><code class="docutils literal notranslate"><span class="pre">chpl</span> <span class="pre">--static</span> <span class="pre">multiple-options.chpl</span></code></p>
<ul>
<li><p>Execution 1:</p>
<p><code class="docutils literal notranslate"><span class="pre">./multiple-options</span> <span class="pre">--x=true</span></code></p>
</li>
<li><p>Execution 2:</p>
<p><code class="docutils literal notranslate"><span class="pre">./multiple-options</span> <span class="pre">--x=false</span></code></p>
</li>
</ul>
</li>
<li><p>Compilation 2:</p>
<p><code class="docutils literal notranslate"><span class="pre">chpl</span> <span class="pre">--dynamic</span> <span class="pre">multiple-options.chpl</span></code></p>
<ul>
<li><p>Execution 3:</p>
<p><code class="docutils literal notranslate"><span class="pre">./multiple-options</span> <span class="pre">--x=true</span></code></p>
</li>
<li><p>Execution 4:</p>
<p><code class="docutils literal notranslate"><span class="pre">./multiple-options</span> <span class="pre">--x=false</span></code></p>
</li>
</ul>
</li>
</ul>
<p>Note that sometimes different execution arguments will result in different
output.  <a class="reference internal" href="#testing-different-behavior-in-different-settings">Testing Different Behavior in Different Settings</a> provides guidance
on how a test could respond to different behavior without modifying the output
that is generated.</p>
</section>
<section id="environment-variables">
<h5>Environment Variables<a class="headerlink" href="#environment-variables" title="Permalink to this heading">¶</a></h5>
<p>Environment variables can be set for a particular test or directory using a
<code class="docutils literal notranslate"><span class="pre">.execenv</span></code> or <code class="docutils literal notranslate"><span class="pre">EXECENV</span></code> file.  Each environment variable must be specified
on a separate line, but all will be set for a particular run.</p>
<p>Here is an example <code class="docutils literal notranslate"><span class="pre">.execenv</span></code> file:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CHPL_RT_NUM_THREADS_PER_LOCALE</span><span class="o">=</span><span class="m">100</span>
</pre></div>
</div>
</div></blockquote>
</section>
</section>
<section id="controlling-how-it-runs">
<h4>Controlling How It Runs<a class="headerlink" href="#controlling-how-it-runs" title="Permalink to this heading">¶</a></h4>
<p>The testing system has a variety of files that can fine tune when a test gets
run.</p>
<p>If the test should only be compiled and not executed, mark it with an empty file
with the suffix <code class="docutils literal notranslate"><span class="pre">.noexec</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">foo.noexec</span></code>.  If the test should not be
compiled or executed on its own (for instance, if it is solely a helper file for
another test), give an empty file with the suffix <code class="docutils literal notranslate"><span class="pre">.notest</span></code>.  A directory with
an empty <code class="docutils literal notranslate"><span class="pre">NOTEST</span></code> file will similarly not be run by the testing system (unless
its contents are explicitly listed in the call to <code class="docutils literal notranslate"><span class="pre">start_test</span></code>).</p>
<section id="running-multiple-times">
<h5>Running Multiple Times<a class="headerlink" href="#running-multiple-times" title="Permalink to this heading">¶</a></h5>
<p>By default, each correctness test is run only once. It is possible to
specify that a test should be run multiple times by providing a <code class="docutils literal notranslate"><span class="pre">.numtrials</span></code>
file for that test, or by passing <code class="docutils literal notranslate"><span class="pre">-num-trials</span></code> to <code class="docutils literal notranslate"><span class="pre">start_test</span></code>.  For
instance, the following file would cause the test to be run 10 times:</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.numtrials</span></code></p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>10
</pre></div>
</div>
</div></blockquote>
<p>Note that a <code class="docutils literal notranslate"><span class="pre">.numtrials</span></code> file will override any explicit <code class="docutils literal notranslate"><span class="pre">-num-trials</span></code> value.</p>
</section>
<section id="limiting-time-taken">
<h5>Limiting Time Taken<a class="headerlink" href="#limiting-time-taken" title="Permalink to this heading">¶</a></h5>
<p>Normally, <code class="docutils literal notranslate"><span class="pre">start_test</span></code> will kill a test that has taken longer than 300 seconds
to execute or has been compiling for longer than four times the execution
timeout value.</p>
<p>The execution timeout value can be overridden for a test by specifying the
number of seconds in a <code class="docutils literal notranslate"><span class="pre">.timeout</span></code> file.  It can be set either higher than the
default timeout (for tests that take an unusually long time to run) or lower
(for tests that are expected to finish very quickly).  The former is used more
frequently, but the latter is useful when diagnosing a test failure - if the
test is usually quick but occasionally hangs, a smaller timeout value can help
speed up the time to run the testing system when the failure mode does occur.</p>
<p>Note that if the value in this file is longer than the global timeout, any
explicit <code class="docutils literal notranslate"><span class="pre">-num-trials</span></code> value or <code class="docutils literal notranslate"><span class="pre">.numtrials</span></code> file will be ignored and the
test will run only once.</p>
</section>
</section>
<section id="tests-with-varying-output">
<h4>Tests With Varying Output<a class="headerlink" href="#tests-with-varying-output" title="Permalink to this heading">¶</a></h4>
<section id="limiting-where-the-test-runs">
<h5>Limiting Where the Test Runs<a class="headerlink" href="#limiting-where-the-test-runs" title="Permalink to this heading">¶</a></h5>
<p>Sometimes a test is only applicable to certain test environments: it might rely
on multi-locale state, or change its behavior dramatically depending on if
optimizations are used, for instance.  If a test is only intended to run in
certain settings, a <code class="docutils literal notranslate"><span class="pre">SKIPIF</span></code> or <code class="docutils literal notranslate"><span class="pre">.skipif</span></code> file should be used.</p>
<p>A directory-wide <code class="docutils literal notranslate"><span class="pre">SKIPIF</span></code> file or a test-specific <code class="docutils literal notranslate"><span class="pre">.skipif</span></code> file can take
two forms.  The first is a line separated list of easily computed conditions,
any one of which will cause the test not to run in that particular setting.  For
instance, the following file would only allow <code class="docutils literal notranslate"><span class="pre">foo.chpl</span></code> to run in a
single-locale setting:</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.skipif</span></code></p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHPL_COMM<span class="w"> </span>!<span class="o">=</span><span class="w"> </span>none
</pre></div>
</div>
</div></blockquote>
<p>This is useful when the conditions required to skip a test can be easily
determined from the environment.  A condition of <code class="docutils literal notranslate"><span class="pre">&lt;=</span></code> indicates that the test
should be skipped when the environment variable on the left contains the
contents on the right, while <code class="docutils literal notranslate"><span class="pre">&gt;=</span></code> indicates the opposite - this is useful for
imprecise matches, e.g. <code class="docutils literal notranslate"><span class="pre">CHPL_HOST_PLATFORM</span> <span class="pre">&gt;=</span> <span class="pre">cygwin</span></code> would cause the test to
run on both <code class="docutils literal notranslate"><span class="pre">cygwin64</span></code> and <code class="docutils literal notranslate"><span class="pre">cygwin32</span></code>.</p>
<p>The second form a <code class="docutils literal notranslate"><span class="pre">.skipif</span></code> or <code class="docutils literal notranslate"><span class="pre">SKIPIF</span></code> file can take is that of a script.
This form is intended for conditions that require some computation to determine,
or when the combination of conditions is necessary (i.e. this setting <strong>and</strong>
this setting are required for the behavior we want to avoid).  The script can be
in any commonly supported scripting language, usually bash or python.  The
<code class="docutils literal notranslate"><span class="pre">.skipif</span></code> or <code class="docutils literal notranslate"><span class="pre">SKIPIF</span></code> file must have executable permissions for this form to
work.  Printing <code class="docutils literal notranslate"><span class="pre">True</span></code> to standard output will result in the test being
skipped, while printing <code class="docutils literal notranslate"><span class="pre">False</span></code> will result in the test being run.</p>
<p>For instance:</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.skipif</span></code></p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;CHPL_TEST_PERF&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;on&#39;</span> <span class="ow">and</span>
      <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;CHPL_ATOMICS&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;locks&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>would cause the test to be skipped when performance testing is done with
CHPL_ATOMICS=locks, but not ordinary performance testing, or correctness
testing with CHPL_ATOMICS=locks</p>
</section>
<section id="testing-different-behavior-in-different-settings">
<h5>Testing Different Behavior in Different Settings<a class="headerlink" href="#testing-different-behavior-in-different-settings" title="Permalink to this heading">¶</a></h5>
<p>If a test is intended to work in all settings but will have slightly different
behavior in some situations, it is appropriate to add additional <code class="docutils literal notranslate"><span class="pre">.good</span></code> files
for those settings.  Some of these additional <code class="docutils literal notranslate"><span class="pre">.good</span></code> files will be used
automatically by the testing system, while others will need to be specified
explicitly in the <code class="docutils literal notranslate"><span class="pre">.compopts</span></code> or <code class="docutils literal notranslate"><span class="pre">.execopts</span></code> file for the test.</p>
<p><code class="docutils literal notranslate"><span class="pre">start_test</span></code> automatically recognizes <code class="docutils literal notranslate"><span class="pre">.good</span></code> files with prefixes for
<code class="docutils literal notranslate"><span class="pre">--no-local</span></code>, communication layer, locale model, and <code class="docutils literal notranslate"><span class="pre">chpldoc</span></code>.  For example:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.comm-none.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">CHPL_COMM=none</span></code> (the unqualified <code class="docutils literal notranslate"><span class="pre">.good</span></code> file
will then apply for CHPL_COMM != none)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.comm-gasnet.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">CHPL_COMM=gasnet</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.comm-ofi.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">CHPL_COMM=ofi</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.comm-ugni.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">CHPL_COMM=ugni</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.no-local.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">--no-local</span></code> testing</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.na-none.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">CHPL_NETWORK_ATOMICS=none</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.tasks-fifo.good</span></code>: used with <code class="docutils literal notranslate"><span class="pre">CHPL_TASKS=fifo</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.doc.good</span></code>: used when testing <code class="docutils literal notranslate"><span class="pre">chpldoc</span></code> instead of <code class="docutils literal notranslate"><span class="pre">chpl</span></code></p></li>
</ul>
<p>Note that <code class="docutils literal notranslate"><span class="pre">.comm-</span></code>, <code class="docutils literal notranslate"><span class="pre">.na-</span></code>, and <code class="docutils literal notranslate"><span class="pre">lm-</span></code> can be combined, in that order.
For instance <code class="docutils literal notranslate"><span class="pre">mytest.comm-none.tasks-fifo.good</span></code>.</p>
<p>Requests can be made for supporting additional formats if a common format
does not appear to be covered automatically.</p>
<p>If only some compilations or executions of a test need a specialized <code class="docutils literal notranslate"><span class="pre">.good</span></code>
file, a comment on the same line as the relevant options can be used.  For
instance:</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.execopts</span></code></p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--x<span class="o">=</span><span class="nb">true</span><span class="w"> </span><span class="c1"># foo.true.good</span>
--x<span class="o">=</span><span class="nb">false</span><span class="w"> </span><span class="c1"># foo.false.good</span>
</pre></div>
</div>
</div></blockquote>
<p>will compare test output to <code class="docutils literal notranslate"><span class="pre">foo.true.good</span></code> for the first execution and
<code class="docutils literal notranslate"><span class="pre">foo.false.good</span></code> for the second.</p>
<p>Any line that is unlabeled will use the default <code class="docutils literal notranslate"><span class="pre">.good</span></code> for that test.
Undefined behavior will occur when both the <code class="docutils literal notranslate"><span class="pre">.compopts</span></code> and <code class="docutils literal notranslate"><span class="pre">.execopts</span></code>
files specify a <code class="docutils literal notranslate"><span class="pre">.good</span></code> file in this way.</p>
<p>If you want to use use default arguments for the test but specify a different
<code class="docutils literal notranslate"><span class="pre">.good</span></code> file, you can add a line in your compopts/execopts file as follows
(note the space before the #):</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># foo.execopts</span>
<span class="w"> </span><span class="c1"># foo.true.good</span>
</pre></div>
</div>
</div></blockquote>
</section>
</section>
<section id="using-precomp-preexec-and-prediff-files">
<h4>Using precomp, preexec, and prediff files<a class="headerlink" href="#using-precomp-preexec-and-prediff-files" title="Permalink to this heading">¶</a></h4>
<p>When creating a <code class="docutils literal notranslate"><span class="pre">.precomp</span></code>, <code class="docutils literal notranslate"><span class="pre">.preexec</span></code>, or <code class="docutils literal notranslate"><span class="pre">.prediff</span></code> file, the file
must be an executable. You can turn your script into an executable by running:
<code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">+x</span> <span class="pre">foo.precomp</span></code>. To specify these files for entire directories,
the files should be named <code class="docutils literal notranslate"><span class="pre">PRECOMP</span></code>, <code class="docutils literal notranslate"><span class="pre">PREEXEC</span></code>, and <code class="docutils literal notranslate"><span class="pre">PREDIFF</span></code>,
respectively.</p>
<p>If you wish to have a system wide <code class="docutils literal notranslate"><span class="pre">.prediff</span></code> file, you can use the
<code class="docutils literal notranslate"><span class="pre">CHPL_SYSTEM_PREDIFF</span></code> environment variable that takes a comma-separated
list of prediffs to run after every test before comparing to the <code class="docutils literal notranslate"><span class="pre">.good</span></code>
file.</p>
</section>
<section id="using-pretest">
<h4>Using PRETEST<a class="headerlink" href="#using-pretest" title="Permalink to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">PRETEST</span></code> allows you to run a script once before any test is run in a
directory. This can be used to set up a test, for example, by generating
<code class="docutils literal notranslate"><span class="pre">.good</span></code> files, or create/build other programs that are used by the test.
The file must be an executable. You can turn your script into an executable by
running: <code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">+x</span> <span class="pre">PRETEST</span></code>.</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">PRETEST</span></code> script will not be run for any subdirectories and
must be either duplicated or have a symbolic link to the parent directory.
You can add a symlink to a file in a parent directory by running:
<code class="docutils literal notranslate"><span class="pre">ln</span> <span class="pre">-s</span> <span class="pre">../PRETEST</span> <span class="pre">PRETEST</span></code></p>
</section>
</section>
<section id="a-performance-test">
<h3>A Performance Test<a class="headerlink" href="#a-performance-test" title="Permalink to this heading">¶</a></h3>
<p>This section covers how to make a performance test, including:</p>
<ul class="simple">
<li><p>how to indicate it is a performance test</p></li>
<li><p>how to specify which parts of the output should be tracked</p></li>
<li><p>how to validate the output</p></li>
<li><p>how to specify compilation and execution options that are different from the
test’s normal run</p></li>
<li><p>how to track output for multiple tests</p></li>
<li><p>how to compare against a version written in C</p></li>
<li><p>how to graph the data that has been tracked</p></li>
</ul>
<p>[Files used to illustrate the running example here can be found at
<a class="reference external" href="https://github.com/chapel-lang/chapel/pull/8971">$CHPL_HOME/test/Samples/Performance</a> in the Chapel source repository]</p>
<section id="identifying-performance-keys">
<h4>Identifying Performance Keys<a class="headerlink" href="#identifying-performance-keys" title="Permalink to this heading">¶</a></h4>
<p>Most of the information above pertains to the creation of a correctness test, in
which the test’s output is compared to a <code class="docutils literal notranslate"><span class="pre">.good</span></code> file.  The testing system
also supports performance tests in which one or more values from a test’s output
can be tracked on a nightly basis and optionally graphed.  Information about
running a performance test can be found in <a class="reference internal" href="#performance-testing">Performance Testing</a>.</p>
<p>Performance tests are specified using a <code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> file, which lists strings
that the test system should look for in the output serving as prefixes for a
piece of data to track.  When crawling a directory hierarchy, only tests with
<code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> files will be considered when testing in performance mode.  For
example, if a test named <code class="docutils literal notranslate"><span class="pre">foo.chpl</span></code> generates output in the following format:</p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Time: 194.3 seconds
Memory: 24GB
Validation: SUCCESS
</pre></div>
</div>
</div></blockquote>
<p>one could track the two numeric values using a <code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> file as
follows:</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.perfkeys</span></code></p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Time:
Memory:
</pre></div>
</div>
</div></blockquote>
<p>As the test system runs, it will look for the specified performance
keys in the test output and store the string following the key as part
of the performance test output (described below).  Note that one could
also track the Validation string in this way, though there are better
ways to track success/failure conditions, described in the next
section.</p>
</section>
<section id="validating-performance-test-output">
<h4>Validating Performance Test Output<a class="headerlink" href="#validating-performance-test-output" title="Permalink to this heading">¶</a></h4>
<p>In addition to identifying key-value pairs to track, performance
testing can also do some simple validation of test output using
regular expression-based matching.  A line starting with
<code class="docutils literal notranslate"><span class="pre">verify:[&lt;line#&gt;:]</span></code> (or <code class="docutils literal notranslate"><span class="pre">reject:[&lt;line#&gt;:]</span></code>) followed by a regular
expression will ensure that the test output contains (does not
contain) the given regular expression, and count any surprises as
failures in the testing results.  The optional line# constrains what
line number the output must appear on, where a negative number
indicates that the counting should start at the end of the file.</p>
<p>For example, adding a third line to the <code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> file, we can also
verify that the last line of output contains the string “SUCCESS”:</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.perfkeys</span></code></p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Time:
Memory:
verify:-1: SUCCESS
</pre></div>
</div>
</div></blockquote>
</section>
<section id="accumulating-performance-data-in-dat-files">
<h4>Accumulating Performance Data in .dat files<a class="headerlink" href="#accumulating-performance-data-in-dat-files" title="Permalink to this heading">¶</a></h4>
<p>The values collected during performance testing are stored in a <code class="docutils literal notranslate"><span class="pre">.dat</span></code> file in
the directory specified by <code class="docutils literal notranslate"><span class="pre">$CHPL_TEST_PERF_DIR</span></code> (if undefined, the test
system defaults to <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/test/perfdat/&lt;machineName&gt;</span></code>).  Each time the
test is run in performance mode, a new line of data is added to the end of the
<code class="docutils literal notranslate"><span class="pre">.dat</span></code> file.  The line will start with the date, and the data for each key
will be tab-separated.  The base name for the <code class="docutils literal notranslate"><span class="pre">.dat</span></code> file is taken from the
<code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> file.  For example, the output for the test above would be stored
in a file named <code class="docutils literal notranslate"><span class="pre">foo.dat</span></code>.</p>
<p>Here is a sample <code class="docutils literal notranslate"><span class="pre">.dat</span></code> file, for the performance test at
<a class="reference external" href="https://github.com/chapel-lang/chapel/pull/8971">$CHPL_HOME/test/Samples/Performance</a>:</p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span># Date     Time:   Memory:
03/26/18   194.3   24
04/02/18   194.3   24
</pre></div>
</div>
</div></blockquote>
<p>Because the lines are tab-separated, the key will not necessarily “line up”
visually with the corresponding header.  Modifying these files by hand is
inadvisable.</p>
<p>Performance tests submitted to the Chapel repository are run on a nightly basis,
generating these <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files.  Modifications to the <code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> that
specify them <strong>will</strong> impact the <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files that have already been
generated, so please be careful when updating already existing performance
tests.</p>
<p>Note that in practice, most tests are written to be run in both a
correctness and a performance mode, using a <code class="docutils literal notranslate"><span class="pre">bool</span> <span class="pre">config</span> <span class="pre">const</span></code> to skip
the printing of nondeterministic data such as the Time (and possibly
Memory) values above.  We tend to make tests run in performance mode
by default and use a <code class="docutils literal notranslate"><span class="pre">foo.execopts</span></code> file to make the correctness testing
flip this switch (since end users will typically want the performance
data on and there’s nothing worse than firing off a long run only to
find you didn’t turn on the performance metrics).</p>
</section>
<section id="other-performance-testing-options">
<h4>Other Performance Testing Options<a class="headerlink" href="#other-performance-testing-options" title="Permalink to this heading">¶</a></h4>
<p>Like correctness testing, performance testing supports the ability to
specify different compiler and execution-time options, etc.  This is
done using files, as in correctness testing, where the filenames tend
to start with <code class="docutils literal notranslate"><span class="pre">PERF*</span></code> or <code class="docutils literal notranslate"><span class="pre">.perf*</span></code>.  For example, <code class="docutils literal notranslate"><span class="pre">foo.perfcompopts</span></code> would
specify compiler options that should be used when compiling the test
for performance mode while <code class="docutils literal notranslate"><span class="pre">foo.perfexecopts</span></code> specifies execution-time
options for performance testing. The number of trials for performance
testing can be specified in a <code class="docutils literal notranslate"><span class="pre">foo.perfnumtrials</span></code> file.</p>
</section>
<section id="comparing-multiple-versions">
<h4>Comparing Multiple Versions<a class="headerlink" href="#comparing-multiple-versions" title="Permalink to this heading">¶</a></h4>
<p>Most performance tests are most interesting when comparing multiple
things to one another – for example, multiple implementations of
an algorithm, a test compiled in various configurations, a Chapel vs.
C version, etc.  The approach typically taken here is to have each
configuration write output to its own <code class="docutils literal notranslate"><span class="pre">.dat</span></code> file and then to graph
columns from various <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files against one another.</p>
<p>To compare multiple distinct Chapel tests, the approach is easy;
simply make each one a performance test with a distinct name.  (In
fact, Chapel performance tests must have unique names across the
entire testing system because all <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files are placed into a single
directory at the end; the system itself checks for conflicts and
complains if it finds any).</p>
<p>To compare a single Chapel test compiled or run in multiple
configurations, the approach taken is to use multi-line versions of
the <code class="docutils literal notranslate"><span class="pre">.perfcompopts</span></code> OR <code class="docutils literal notranslate"><span class="pre">.perfexecopts</span></code> files, where each line represents a
different configuration that should be tested.  Each option line
should be concluded with a <code class="docutils literal notranslate"><span class="pre">#</span></code> comment delimiter, after which a
<code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> file should be named.  For example, to compare two
problem sizes, one might use:</p>
<p><code class="docutils literal notranslate"><span class="pre">bar.perfexecopts</span></code></p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--n=100    # bar-100.perfkeys
--n=10000  # bar-10000.perfkeys
</pre></div>
</div>
</div></blockquote>
<p>This would cause <code class="docutils literal notranslate"><span class="pre">bar.chpl</span></code> to be compiled once and executed twice, one
with <code class="docutils literal notranslate"><span class="pre">--n=100</span></code> and the second time with <code class="docutils literal notranslate"><span class="pre">--n=10000</span></code>.  The first execution
would use <code class="docutils literal notranslate"><span class="pre">bar-100.perfkeys</span></code> for its performance keys and write its
output to <code class="docutils literal notranslate"><span class="pre">bar-100.dat</span></code> while the second would use <code class="docutils literal notranslate"><span class="pre">bar-10000.perfkeys</span></code>
and write its output to <code class="docutils literal notranslate"><span class="pre">bar-10000.dat</span></code>.</p>
<section id="comparing-to-a-c-version">
<h5>Comparing to a C version<a class="headerlink" href="#comparing-to-a-c-version" title="Permalink to this heading">¶</a></h5>
<p>To compare a C version of a test to a Chapel version, the C version of the test
must end with the suffix <code class="docutils literal notranslate"><span class="pre">.test.c</span></code> for single locale tests and <code class="docutils literal notranslate"><span class="pre">.ml-test.c</span></code>
for multilocale tests.  Since <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files must have unique names, the base
name for the C test should vary from the Chapel equivalent.  For example, I
might name the C version of the <code class="docutils literal notranslate"><span class="pre">foo.chpl</span></code> performance test <code class="docutils literal notranslate"><span class="pre">foo-c.test.c</span></code>.
Like any other test, the C test needs a <code class="docutils literal notranslate"><span class="pre">.good</span></code> file for correctness testing
and a <code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> file for performance testing.</p>
<p>C versions do not have to be performance tests, but this is their most common
use case.</p>
</section>
</section>
<section id="creating-a-graph-comparing-multiple-variations">
<h4>Creating a graph comparing multiple variations<a class="headerlink" href="#creating-a-graph-comparing-multiple-variations" title="Permalink to this heading">¶</a></h4>
<p>Once you are creating multiple <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files containing data you would
like to graph, you’ll create a <code class="docutils literal notranslate"><span class="pre">.graph</span></code> file indicating which data from
which <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files should be graphed.  For example, to compare the
timing data from the <code class="docutils literal notranslate"><span class="pre">foo.chpl</span></code> and <code class="docutils literal notranslate"><span class="pre">foo-c.c</span></code> tests described above, one
might use the following <code class="docutils literal notranslate"><span class="pre">foo.graph</span></code> file (note that the graph file’s
basename need not have any relation to the tests it is graphing since
they are typically pulling from multiple <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files; making the
filename useful to human readers is the main consideration).</p>
<p><code class="docutils literal notranslate"><span class="pre">foo.graph</span></code></p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>perfkeys: Time:, Time:
files: foo.dat, foo-c.dat
graphkeys: Chapel version, C version
ylabel: Time (seconds)
graphtitle: Sample Performance Test (Bogus)
</pre></div>
</div>
</div></blockquote>
<p>Briefly, the following three entries need to have the same arity,
corresponding to the lines in the graph:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">perfkeys:</span></code> is a comma-separated list of perfkeys to graph from…</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">files:</span></code> …the comma-separated list of .dat files, respectively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graphkeys:</span></code> this is a comma-separated list of strings to use in the
graph’s legend.</p></li>
</ul>
<p>The following two entries are singletons:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ylabel:</span></code> a label for the graph’s y-axis (the x-axis will be the date the
test was run by default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graphtitle:</span></code> a title for the graph as a whole</p></li>
</ul>
<p>Finally, add the <code class="docutils literal notranslate"><span class="pre">.graph</span></code> file to <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/test/GRAPHFILES</span></code>.  This file
is separated into a number of suites (indicated by comments) followed by graphs
that should appear in those suites (a graph may appear in multiple suites).
This file determines how graphs are organized on the Chapel performance graphing
webpages (currently hosted at <code class="docutils literal notranslate"><span class="pre">http://chapel-lang.org/perf/</span></code>).</p>
<p>Once the <code class="docutils literal notranslate"><span class="pre">.graph</span></code> file exists and is listed in <code class="docutils literal notranslate"><span class="pre">GRAPHFILES</span></code>, running
<code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">-performance</span></code> will cause the test system to not only create
the <code class="docutils literal notranslate"><span class="pre">.dat</span></code> files, but also to create a graph as described in the .graph
file.  To view the graph, point your browser to
<code class="docutils literal notranslate"><span class="pre">$CHPL_TEST_PERF_DIR/&lt;machinename&gt;/html/index.html</span></code>.  Then select the
suite(s) in which your graph appears, and you should see data for it.
(Note that for a new graph with only one day of data, it can be hard
to see the singleton points at first).</p>
</section>
<section id="multilocale-performance-testing">
<h4>Multilocale Performance Testing<a class="headerlink" href="#multilocale-performance-testing" title="Permalink to this heading">¶</a></h4>
<p>Writing a performance test for multilocale setting has similarities to single
locale performance testing and multilocale correctness testing. However, helper
file suffixes differ from the previously covered ones as follows:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Single Locale Performance</p></th>
<th class="head"><p>Multilocale Performance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.perfexecopts</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ml-execopts</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.perfcompopts</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ml-compopts</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ml-keys</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.graph</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ml-perf.graph</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.execenv</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ml-execenv</span></code></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Multilocale Correctness</p></th>
<th class="head"><p>Multilocale Performance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.numlocales</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ml-numlocales</span></code></p></td>
</tr>
</tbody>
</table>
<p>Graph files for multilocale performance tests are listed in <code class="docutils literal notranslate"><span class="pre">ML-GRAPHFILES</span></code>
instead of <code class="docutils literal notranslate"><span class="pre">GRAPHFILES</span></code>.</p>
<p>Finally to run a multilocale performance test <code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">--perflabel</span> <span class="pre">ml-</span></code>
must be used.</p>
</section>
<section id="multilocale-communication-counts-testing">
<h4>Multilocale Communication Counts Testing<a class="headerlink" href="#multilocale-communication-counts-testing" title="Permalink to this heading">¶</a></h4>
<p>Another type of multilocale testing is where the number of communication calls
(e.g. GETs, PUTs, ONs) generated is tracked. These numbers can be obtained with
the help of <a class="reference external" href="https://chapel-lang.org/docs/modules/standard/CommDiagnostics.html">CommDiagnostics</a> module and be printed out similar to printing out
the time elapsed or throughput.</p>
<p>Communication counts testing is only applicable in a multilocale setting, and it
is similar to multilocale performance testing. However, for helper files <code class="docutils literal notranslate"><span class="pre">cc-</span></code>
label is used instead of <code class="docutils literal notranslate"><span class="pre">ml-</span></code>.</p>
</section>
<section id="test-your-test-before-submitting">
<h4>Test Your Test Before Submitting<a class="headerlink" href="#test-your-test-before-submitting" title="Permalink to this heading">¶</a></h4>
<p>Before submitting your test for review, be sure that it works under</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">start_test</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">--performance</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">--perflabel</span> <span class="pre">ml-</span></code> (if applicable)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">--perflabel</span> <span class="pre">cc-</span></code> (if applicable)</p></li>
</ul>
<p>modes when running within the directory (or directories) in question. Nothing is
more embarrassing than committing a test that doesn’t work on day one.</p>
<p>Once the test(s), <code class="docutils literal notranslate"><span class="pre">.graph</span></code> files, and <code class="docutils literal notranslate"><span class="pre">GRAPHFILES</span></code> are committed to the
Chapel repository, they will start showing up on the Chapel public
pages as well.</p>
</section>
</section>
<section id="a-test-that-tracks-a-failure">
<h3>A Test That Tracks A Failure<a class="headerlink" href="#a-test-that-tracks-a-failure" title="Permalink to this heading">¶</a></h3>
<p>The testing system also serves as our current system for tracking code-driven
bugs and open issues.  When a bug is encountered (either by a user or a
developer), if it is not quickly resolved then it will be tracked by making what
is known as a future.</p>
<p>When making a new test that is a future, follow the guidelines for making a
correctness test.  Like normal correctness tests, a future will specify a
<code class="docutils literal notranslate"><span class="pre">.good</span></code> file with its intended output.  However, the future is not expected to
match against the <code class="docutils literal notranslate"><span class="pre">.good</span></code> file when the future is filed - developer effort is
usually required to fix the bug.</p>
<p>Once this test is created (or if a test already exists), add a <code class="docutils literal notranslate"><span class="pre">.future</span></code> file
sharing the same base name as the test to mark it as a future.  For example,
adding a <code class="docutils literal notranslate"><span class="pre">hi.future</span></code> file would make the simple correctness test at the start
of this document into a future test.</p>
<p>Marking a test as a future causes it to be tested every night, but not to be
counted against the compiler’s success/failure statistics.  If/when the future
matches its <code class="docutils literal notranslate"><span class="pre">.good</span></code> file, developers will be alerted by the testing system.</p>
<p>The format of the <code class="docutils literal notranslate"><span class="pre">.future</span></code> file itself is minimally structured. The
first line should contain the type of future (see list below) followed
by a brief (one 80-column line) description of the future, which ideally
reflects the associated GitHub issue title. The next line should contain the
associated GitHub issue number in the <cite>#issue-number</cite> format, e.g. <cite>#1</cite>.</p>
<p>The rest of the file is optional and free-form. It can be used over the
future’s lifetime to describe in what way the test isn’t working or should be
working, implementation notes, philosophical arguments, etc.</p>
<p>The current categories of futures reflect GitHub labels:</p>
<ul class="simple">
<li><p><strong>bug</strong>: this test exhibits a bug in the implementation</p></li>
<li><p><strong>error message</strong>: this test correctly generates an error message, but the
error message needs clarification/improvement</p></li>
<li><p><strong>feature request</strong>: a way of filing a request for a particular feature in
Chapel</p></li>
<li><p><strong>performance</strong>: indicates a performance issue that needs to be addressed</p></li>
<li><p><strong>design</strong>: this test raises a question about Chapel’s semantics that we
ultimately need to address</p></li>
<li><p><strong>portability</strong>: indicates a portability issue that needs to be addressed</p></li>
<li><p><strong>unimplemented feature</strong>: this test uses features that are specified, but
which have not yet been implemented.</p></li>
</ul>
<section id="github-issues">
<h4>GitHub Issues<a class="headerlink" href="#github-issues" title="Permalink to this heading">¶</a></h4>
<p>Currently, it is mandatory to include a GitHub issue number with any new
futures. That said, futures that pre-date Chapel’s adoption of GitHub issues may
have a description instead of an issue number.</p>
<p>When filing a bug report as an issue, it is considered good practice to
include a future for the issue tracked on the <a class="reference external" href="https://github.com/chapel-lang/chapel/issues">GitHub issues page</a>.</p>
</section>
<section id="tracking-current-failure-mode">
<h4>Tracking Current Failure Mode<a class="headerlink" href="#tracking-current-failure-mode" title="Permalink to this heading">¶</a></h4>
<p>Sometimes a future will change its behavior, but not be resolved.  The future
should be updated to continue to track the issue as much as possible - to alert
developers when this happens, it is necessary to track not only the expected
good output but also the output indicating the current failure.  This is done
via a <code class="docutils literal notranslate"><span class="pre">.bad</span></code> file.  The contents of a <code class="docutils literal notranslate"><span class="pre">.bad</span></code> file are similar to a <code class="docutils literal notranslate"><span class="pre">.good</span></code>
file and should match the currently generated output of the test.</p>
<p>Tests whose current/<code class="docutils literal notranslate"><span class="pre">.bad</span></code> output varies based on the compiler version number,
line numbers of standard modules and such are fragile since these things change
frequently; in such cases, either a <code class="docutils literal notranslate"><span class="pre">.prediff</span></code> should be used to filter the
output before comparing to <code class="docutils literal notranslate"><span class="pre">.bad</span></code>, or the <code class="docutils literal notranslate"><span class="pre">.bad</span></code> should be omitted.
Ultimately, our intention is to support a library of common recipes for <code class="docutils literal notranslate"><span class="pre">.bad</span></code>
files, but this has not been implemented yet.</p>
<p>An easy way to obtain this file is to run the future once using <code class="docutils literal notranslate"><span class="pre">start_test</span></code> -
the output for that configuration can then be found in a <code class="docutils literal notranslate"><span class="pre">.out.tmp</span></code> file in
the same directory as the test.</p>
</section>
<section id="resolving-a-future">
<h4>Resolving a Future<a class="headerlink" href="#resolving-a-future" title="Permalink to this heading">¶</a></h4>
<p>There are three situations under which a future will get resolved.</p>
<ol class="arabic simple">
<li><p>A developer explicitly works on resolving the future.</p></li>
<li><p>A developer works on another feature or issue and as a consequence the future
gets resolved.</p>
<ul class="simple">
<li><p>This could happen if the two issues appeared to be unrelated, or if the
existence of the future had been forgotten</p></li>
</ul>
</li>
<li><p>A developer examines the future and determines the current behavior is correct</p>
<ul class="simple">
<li><p>The developer may then either remove the supporting files for futures, or
remove the test entirely.</p></li>
</ul>
</li>
</ol>
</section>
</section>
</section>
<section id="invoking-start-test">
<h2>Invoking start_test<a class="headerlink" href="#invoking-start-test" title="Permalink to this heading">¶</a></h2>
<p>A brief description of flags that can be used with <code class="docutils literal notranslate"><span class="pre">start_test</span></code> itself can
be obtained by calling <code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">-h</span></code>.</p>
<section id="correctness-testing">
<h3>Correctness Testing<a class="headerlink" href="#correctness-testing" title="Permalink to this heading">¶</a></h3>
<p>The section titled <a class="reference internal" href="#a-correctness-test">A Correctness Test</a> demonstrates invoking <code class="docutils literal notranslate"><span class="pre">start_test</span></code>
on a single explicitly-named file.  More generally, <code class="docutils literal notranslate"><span class="pre">start_test</span></code> takes a list
of test and directory names on the command line and will run all tests
explicitly named or contained within the directories (or their subdirectories).
For example:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">foo.chpl</span> <span class="pre">bar/baz.chpl</span> <span class="pre">typeTests/</span> <span class="pre">OOPTests/</span></code></p>
</div></blockquote>
<p>will test the two explicitly-named tests (<code class="docutils literal notranslate"><span class="pre">foo.chpl</span></code> and <code class="docutils literal notranslate"><span class="pre">baz.chpl</span></code> stored
in the <code class="docutils literal notranslate"><span class="pre">bar/</span></code> directory).  It will also recursively search for any tests
stored in the <code class="docutils literal notranslate"><span class="pre">typeTests/</span></code> and <code class="docutils literal notranslate"><span class="pre">OOPTests/</span></code> subdirectories.</p>
<p>If invoked without any arguments, <code class="docutils literal notranslate"><span class="pre">start_test</span></code> will start in the current
directory and recursively look for tests in subdirectories.</p>
<p>If invoked with the <code class="docutils literal notranslate"><span class="pre">--valgrindexe</span></code> flag, <code class="docutils literal notranslate"><span class="pre">start_test</span></code> will compile the
program and execute it with <code class="docutils literal notranslate"><span class="pre">valgrind</span></code>. The <code class="docutils literal notranslate"><span class="pre">--valgrind</span></code> flag does the
same, plus it also runs the compiler under <code class="docutils literal notranslate"><span class="pre">valgrind</span></code>, which increases
testing time compared to <code class="docutils literal notranslate"><span class="pre">--valgrindexe</span></code>. To learn about best practices
with <code class="docutils literal notranslate"><span class="pre">valgrind</span></code>, see <code class="docutils literal notranslate"><span class="pre">Valgrind.rst</span></code>.</p>
<section id="parallel-testing">
<h4>Parallel Testing<a class="headerlink" href="#parallel-testing" title="Permalink to this heading">¶</a></h4>
<p>To run correctness tests in parallel, <code class="docutils literal notranslate"><span class="pre">paratest.local</span></code> can be invoked directly.
For example:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">(cd</span> <span class="pre">$CHPL_HOME/test</span> <span class="pre">&amp;&amp;</span> <span class="pre">$CHPL_HOME/util/test/paratest.local</span> <span class="pre">-dirs</span> <span class="pre">deprecated</span> <span class="pre">-dirs</span> <span class="pre">unstable)</span></code></p>
</div></blockquote>
<p>This command will run all tests in <code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/test/deprecated</span></code> and
<code class="docutils literal notranslate"><span class="pre">$CHPL_HOME/test/deprecated</span></code> using 10 processes. Note that the parallelism is
at the directory level granularity, so if a directory is flat (containing only
files) it will still run serially with this command.</p>
</section>
<section id="gpu-testing">
<h4>GPU Testing<a class="headerlink" href="#gpu-testing" title="Permalink to this heading">¶</a></h4>
<p>To run tests with the GPU locale model, the environment variable
<code class="docutils literal notranslate"><span class="pre">CHPL_TEST_GPU</span></code> needs to be set. For more information on running tests with
GPUs, see the <a class="reference internal" href="../../technotes/gpu.html#readme-gpu"><span class="std std-ref">GPU tech note</span></a>.</p>
</section>
</section>
<section id="performance-testing">
<h3>Performance Testing<a class="headerlink" href="#performance-testing" title="Permalink to this heading">¶</a></h3>
<p>To run performance testing, add the <code class="docutils literal notranslate"><span class="pre">--performance</span></code> flag to <code class="docutils literal notranslate"><span class="pre">start_test</span></code>
along with the traditional options.  So for example, to run this
single test in performance mode, one could use:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">start_test</span> <span class="pre">--performance</span> <span class="pre">foo.chpl</span></code></p>
</div></blockquote>
<p>When crawling a directory hierarchy, only tests with <code class="docutils literal notranslate"><span class="pre">.perfkeys</span></code> files
will be considered when testing in performance mode.</p>
<p>All performance tests are compiled with <code class="docutils literal notranslate"><span class="pre">--fast</span></code> by default and <code class="docutils literal notranslate"><span class="pre">--static</span></code>
when it’s not problematic for the target configuration.</p>
</section>
<section id="sample-output">
<h3>Sample Output<a class="headerlink" href="#sample-output" title="Permalink to this heading">¶</a></h3>
<p>The output from a <code class="docutils literal notranslate"><span class="pre">start_test</span></code> run will begin with a list of the settings
used, following the environment settings as obtained from <code class="docutils literal notranslate"><span class="pre">printchplenv</span></code> (see
<a class="reference external" href="https://chapel-lang.org/docs/usingchapel/chplenv.html">Setting up Your Environment for Chapel</a>).  This will be followed by
information from running the individual tests or directories.</p>
<p>The output from <code class="docutils literal notranslate"><span class="pre">start_test</span></code> will end with the location of the log file
containing all the output from its execution, as well as a summary of all tests
that failed and any futures that were run.  This will look something like this:</p>
<blockquote>
<div><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[Test Summary - 180328.134706]
[Error matching program output for path/to/failing/correctness/test]
Future (bug: description of bug from future file) [Error matching program output for path/to/failing/future]
Future (bug: description of bug from future file) [Success matching program output for path/to/passing/future]
[Summary: #Successes = 1 | #Failures = 1 | #Futures = 2 | #Warnings = 0 ]
[Summary: #Passing Suppressions = 0 | #Passing Futures = 1 ]
[END]
</pre></div>
</div>
</div></blockquote>
<p>Successful tests will not be printed after the line beginning with <code class="docutils literal notranslate"><span class="pre">[Test</span>
<span class="pre">Summary</span></code> unless they had a <code class="docutils literal notranslate"><span class="pre">.future</span></code> file (see <a class="reference internal" href="#a-test-that-tracks-a-failure">A Test That Tracks A
Failure</a> for information about <code class="docutils literal notranslate"><span class="pre">.future</span></code> files).</p>
<p>When nightly testing is run, core developers will be notified of every
configuration with a new failure, warning, passing suppression, and/or
passing future.</p>
</section>
</section>
<section id="summary-of-testing-files">
<h2>Summary of Testing Files<a class="headerlink" href="#summary-of-testing-files" title="Permalink to this heading">¶</a></h2>
<p>The following table serves as a quick reference for the various test files, and
as a table of contents for this page.  It is not necessarily complete, and not
all of it has been covered in this document.  Please ask a member of the core
team for more information on a specific file.</p>
<p>Using file base name, <code class="docutils literal notranslate"><span class="pre">foo</span></code> for the filenames in this table.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>File</p></th>
<th class="head"><p>Contents of file</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td colspan="2"><p><strong>correctness</strong></p></td>
</tr>
<tr class="row-odd"><td><p>foo.chpl</p></td>
<td><p>Chapel test program to compile and run</p></td>
</tr>
<tr class="row-even"><td><p>foo.test.c</p></td>
<td><p>Single locale C test program to compile and run. See
<a class="reference internal" href="#comparing-to-a-c-version">Comparing to a C version</a> for more information</p></td>
</tr>
<tr class="row-odd"><td><p>foo.ml-test.c</p></td>
<td><p>Multilocale C test program to compile and run.  See
<a class="reference internal" href="#comparing-to-a-c-version">Comparing to a C version</a> for more information</p></td>
</tr>
<tr class="row-even"><td><p>foo.good</p></td>
<td><p>expected output of test program</p></td>
</tr>
<tr class="row-odd"><td colspan="2"></td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Test Settings</strong></p></td>
</tr>
<tr class="row-odd"><td><p>foo.compopts</p></td>
<td><p>line separated compiler flag configurations.  See
<a class="reference internal" href="#compile-time-arguments">Compile-time Arguments</a> for more information</p></td>
</tr>
<tr class="row-even"><td><p>COMPOPTS</p></td>
<td><p>directory-wide compiler flags</p></td>
</tr>
<tr class="row-odd"><td><p>foo.execopts</p></td>
<td><p>line separated runtime flag configurations.  See
<a class="reference internal" href="#execution-time-arguments">Execution-time Arguments</a> for more information</p></td>
</tr>
<tr class="row-even"><td><p>EXECOPTS</p></td>
<td><p>directory-wide runtime flags</p></td>
</tr>
<tr class="row-odd"><td><p>foo.execenv</p></td>
<td><p>line separated list of environment variables settings.  See
<a class="reference internal" href="#environment-variables">Environment Variables</a> for more information</p></td>
</tr>
<tr class="row-even"><td><p>EXECENV</p></td>
<td><p>directory-wide environment variables</p></td>
</tr>
<tr class="row-odd"><td><p>foo.numlocales</p></td>
<td><p>number of locales to use in multilocale run</p></td>
</tr>
<tr class="row-even"><td><p>NUMLOCALES</p></td>
<td><p>directory-wide number of locales to use in multilocale run</p></td>
</tr>
<tr class="row-odd"><td colspan="2"></td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Helper files</strong></p></td>
</tr>
<tr class="row-odd"><td><p>foo.catfiles</p></td>
<td><p>line separated list of files to include when validating the
expected output</p></td>
</tr>
<tr class="row-even"><td><p>CATFILES</p></td>
<td><p>directory-wide list of files to compare with output</p></td>
</tr>
<tr class="row-odd"><td><p>foo.prediff</p></td>
<td><p>script that is run on the test output, before taking the
diff between the output and .good file</p></td>
</tr>
<tr class="row-even"><td><p>PREDIFF</p></td>
<td><p>directory-wide script that is run over test output</p></td>
</tr>
<tr class="row-odd"><td><p>foo.precomp</p></td>
<td><p>script that is run prior to compilation of the test program</p></td>
</tr>
<tr class="row-even"><td><p>PRECOMP</p></td>
<td><p>directory-wide script that is run prior to compilation</p></td>
</tr>
<tr class="row-odd"><td><p>foo.preexec</p></td>
<td><p>script that is run prior to execution of the test program</p></td>
</tr>
<tr class="row-even"><td><p>PREEXEC</p></td>
<td><p>directory-wide script that is run prior to execution</p></td>
</tr>
<tr class="row-odd"><td><p>PRETEST</p></td>
<td><p>script that is run once per directory prior to any test being
run</p></td>
</tr>
<tr class="row-even"><td colspan="2"></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Testing System Settings</strong></p></td>
</tr>
<tr class="row-even"><td><p>foo.cleanfiles</p></td>
<td><p>line separated list of files to remove before the next test run</p></td>
</tr>
<tr class="row-odd"><td><p>CLEANFILES</p></td>
<td><p>directory-wide list of files to remove before test runs</p></td>
</tr>
<tr class="row-even"><td><p>foo.noexec</p></td>
<td><p>empty file. Indicates .chpl file should only be compiled,
not executed.  See <a class="reference internal" href="#controlling-how-it-runs">Controlling How It Runs</a> for more
information.</p></td>
</tr>
<tr class="row-odd"><td><p>NOEXEC</p></td>
<td><p>Indicates all .chpl files in this directory should only be
compiled, not executed.</p></td>
</tr>
<tr class="row-even"><td><p>foo.notest</p></td>
<td><p>empty file. Indicates the file should not be run explicitly
See <a class="reference internal" href="#controlling-how-it-runs">Controlling How It Runs</a> for more information.</p></td>
</tr>
<tr class="row-odd"><td><p>NOTEST</p></td>
<td><p>empty file. Indicates the directory should not be run</p></td>
</tr>
<tr class="row-even"><td><p>foo.skipif</p></td>
<td><p>line separated list of conditions under which the test
should not be run, or a script to compute the same.  See
<a class="reference internal" href="#limiting-where-the-test-runs">Limiting Where the Test Runs</a> for more information</p></td>
</tr>
<tr class="row-odd"><td><p>SKIPIF</p></td>
<td><p>same as above, but applied to the entire directory</p></td>
</tr>
<tr class="row-even"><td><p>foo.suppressif</p></td>
<td><p>line separated list of conditions under which the test is
expected to fail, or a script to compute the same.  Note
that unless otherwise specified, a <code class="docutils literal notranslate"><span class="pre">.skipif</span></code> or
<code class="docutils literal notranslate"><span class="pre">.future</span></code> is likely more appropriate for the test.</p></td>
</tr>
<tr class="row-odd"><td><p>foo.timeout</p></td>
<td><p>time in seconds after which start_test should stop this test
See <a class="reference internal" href="#limiting-time-taken">Limiting Time Taken</a> for more information</p></td>
</tr>
<tr class="row-even"><td><p>foo.numtrials</p></td>
<td><p>number of execution trials to run</p></td>
</tr>
<tr class="row-odd"><td><p>NUMTRIALS</p></td>
<td><p>directory-wide number of execution trials to run</p></td>
</tr>
<tr class="row-even"><td colspan="2"></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>performance</strong> (replace “perf” with “ml-” and “cc-” as necessary)</p></td>
</tr>
<tr class="row-even"><td><p>foo.perfcompopts</p></td>
<td><p>compiler flags, overrides .compopts for –performance</p></td>
</tr>
<tr class="row-odd"><td><p>PERFCOMPOPTS</p></td>
<td><p>directory-wide performance compiler flags</p></td>
</tr>
<tr class="row-even"><td><p>foo.perfexecopts</p></td>
<td><p>runtime flags, overrides .execopts for –performance</p></td>
</tr>
<tr class="row-odd"><td><p>PERFEXECOPTS</p></td>
<td><p>directory-wide performance runtime flags</p></td>
</tr>
<tr class="row-even"><td><p>foo.perfexecenv</p></td>
<td><p>environment variables, overrides .execenv for –performance</p></td>
</tr>
<tr class="row-odd"><td><p>PERFEXECENV</p></td>
<td><p>directory-wide performance environment variables</p></td>
</tr>
<tr class="row-even"><td><p>foo.perfnumtrials</p></td>
<td><p>number of execution trials to run if no timeout specified</p></td>
</tr>
<tr class="row-odd"><td><p>PERFNUMTRIALS</p></td>
<td><p>directory-wide number of execution trials to run</p></td>
</tr>
<tr class="row-even"><td><p>foo.perftimeout</p></td>
<td><p>time in seconds after which start_test should stop this test</p></td>
</tr>
<tr class="row-odd"><td><p>foo.perfkeys</p></td>
<td><p>keys to search for in the output</p></td>
</tr>
<tr class="row-even"><td><p>foo.graph</p></td>
<td><p>Specifies which data files and perfkeys to graph, and
contains meta-data associated with labeling data sets,
axis, and graphs</p></td>
</tr>
<tr class="row-odd"><td><p>test/GRAPHFILES</p></td>
<td><p>Acts as an index that tracks all .graph that should be
graphed.</p></td>
</tr>
<tr class="row-even"><td colspan="2"></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>futures</strong></p></td>
</tr>
<tr class="row-even"><td><p>foo.future</p></td>
<td><p>Describes the future being tested, following the
newline-separated format of:
<em>category</em>, <em>title</em>, <em>issue #</em></p></td>
</tr>
<tr class="row-odd"><td><p>foo.bad</p></td>
<td><p>output generated on a failing test, to track if a known
failing future begins failing a different way.  See
<a class="reference internal" href="#tracking-current-failure-mode">Tracking Current Failure Mode</a> for more information</p></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="CHPL_DEVELOPER.html" class="btn btn-neutral float-left" title="The CHPL_DEVELOPER environment variable" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="SpellChecking.html" class="btn btn-neutral float-right" title="chplspell" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Hewlett Packard Enterprise Development LP.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 



</body>
</html>