<!DOCTYPE html>
<html data-theme="light" lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#00cbff">
    
    <meta name="description" content="An archival post from the IEEE TCSC blog in 2012 with a modern reflection on it">
    

    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css" media="screen,print">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
    
    
    
    
    
    
    <style>.sidenote-checkbox { display: none; }</style>
    <style>.feather { width: 1rem; height: 1rem; }</style>
    <link rel="stylesheet" href="../../scss/style.min.css" media="screen,print">
    <link rel="stylesheet" href="../../scss/sidenotes.min.css" media="screen,print">
    <link rel="stylesheet" href="../../css/syntax.min.css" media="screen,print">
    <link rel="stylesheet" href="../../scss/syntax-terminal.min.css" media="screen,print">
    <link rel="stylesheet" href="../../scss/code.min.css" media="screen,print">
    <link rel="icon" type="image/png" href="../../img/favicon.ico">

    <script src="../../js/dropdown-menu.js" defer></script>

    <title>10 Myths About Scalable Parallel Programming Languages (Redux),  Part 1: Productivity and Performance</title>
</head>
<body>
<header>
    
    <div class="container">
        <a class="site-title" href="../../">
            <img alt="Chapel logo" width="50" height="50" src="../../img/logo.png">
            <h1>Chapel Language Blog</h1>
        </a>
    </div>
    <nav id="Header">
        <div class="container">
            <a href="../../about">About</a>
            <a href="https://chapel-lang.org">Chapel Website</a>
            <a href="../../featured">Featured</a>
            <a href="../../series">Series</a>
            <a href="../../tags">Tags</a>
            <a href="../../authors">Authors</a>
            <a href="../../posts">All Posts</a>
        </div>
    </nav>
    
</header>
<main class="container">
<h2>10 Myths About Scalable Parallel Programming Languages (Redux),  Part 1: Productivity and Performance</h2>
<div class="post-subscript">
    <p>Posted on April 30, 2025.</p>
    <p>
        Tags:
        
        <a class="button" href="../../tags/editorial">Editorial</a>
        
        <a class="button" href="../../tags/archival-posts-/-reprints">Archival Posts / Reprints</a>
        
    </p>
    <p>
    By:
    <a href="../../authors/brad-chamberlain">Brad Chamberlain</a>
    </p>
</div>

<div class="post-content">
    
    <div class="table-of-contents">
        <div class="wrapper">
            <span class="header">Table of Contents</span>
            <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction-to-this-series">Introduction to this Series</a></li>
    <li><a href="#the-original-article-reprinted">The Original Article, Reprinted</a>
      <ul>
        <li><a href="#myth-1-productivity-is-at-odds-with-performance">Myth #1: Productivity is at odds with performance</a></li>
        <li><a href="#references">References</a></li>
        <li><a href="#acknowledgments">Acknowledgments</a></li>
      </ul>
    </li>
    <li><a href="#reflections-on-the-original-article">Reflections on the Original Article</a>
      <ul>
        <li><a href="#the-sparse-example">The Sparse Example</a></li>
        <li><a href="#the-type-inference-example">The Type Inference Example</a></li>
        <li><a href="#wrapping-up">Wrapping Up</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
    </div>
    

    

    <h3 id="introduction-to-this-series">
  <a href="#introduction-to-this-series">Introduction to this Series</a>
</h3>
<p>In March 2012, I was invited by Yong Chen, who at that time was the
Newsletter Editor for the IEEE Technical Community on Scalable
Computing (TCSC), to write a short post about Chapel to be published
on the organization&rsquo;s blog.  In considering the invitation, I came up
with a theme that I liked, which was to address a number of skeptical
reactions about developing new programming languages for
high-performance computing (HPC) that our team frequently encountered,
and that I felt were off-base.  The idea was to push back on those
assertions and offer a counter-narrative.  I came up with an initial
list of such attitudes, named the article &ldquo;Myths about Scalable
Parallel Programming Languages&rdquo;, and started writing.</p>
<p>However, as is often the case, I drastically underestimated how
succinctly I could make my points.  By the time I&rsquo;d addressed the
first myth, I&rsquo;d already exhausted my word count budget.  As a result,
the original article turned into a series of eight that were published
between April and November of 2012 and ended up addressing ten myths.
I don&rsquo;t recall whether I had any sense of how large the series'
audience was, but I did receive appreciative comments from readers and
IEEE leadership..</p>
<p>Over time, the IEEE TCSC blog fell into disrepair, and with it, the
series <span class="sidenote"><label class="sidenote-label" for="sidenote-0">became unavailable to the public</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-0"></input><span class="sidenote-content sidenote-right"><span class="sidenote-delimiter">[note:</span>
Well, almost.  In writing this, I've learned that 7/8 of the series <a
href =
"https://web.archive.org/web/20160308062654/https://www.ieeetcsc.org/activities/blog/myths_about_scalable_parallel_programming_languages_part1">can
be found</a> on the <a href = "https://web.archive.org/">Internet
Archive Wayback Machine</a>.<span class="sidenote-delimiter">]</span></span></span>.  Ever since we launched
this blog for Chapel, I&rsquo;ve thought about re-publishing the original
series here for archival purposes, while also taking the opportunity
to consider how well or poorly it has held up over time.  Would our
current team still agree with my original arguments?  Has Chapel now
demonstrated things that I was only speculating about at the time?
Can I even bear to re-read my own writing?  After recently noting that
the 13-year anniversary of the first article was approaching, I
decided that this was as good a time as any to begin.</p>
<p>To that end, welcome to <em>10 Myths About Scalable Parallel Programming
Languages (Redux)</em>, a new series that will re-publish the original
articles along with commentary that provides a current perspective on
the material.  In reproducing this series, I am striving to keep the
content as similar as possible to what was originally published on the
IEEE TCSC blog, updated to use the Chapel blog&rsquo;s formatting
conventions.  Along the way, I intend to fix any typographical issues,
and to update broken hyperlinks to refer to a file&rsquo;s current location
or a reasonable modern-day equivalent.  Most importantly, I&rsquo;ll
decorate the original articles with side-notes, detail sections, and
a closing discussion to capture some current thoughts and updates.</p>
<p>In kicking off this endeavor, I&rsquo;d like to thank Yong Chen, Pavan
Balaji, Xian-He Sun, and IEEE TCSC for providing the motivation and
platform that enabled me to write the original series.</p>
<p>And with that introduction, here is the first article from the series,
originally published on April 30, 2012:</p>
<hr>
<h3 id="the-original-article-reprinted">
  <a href="#the-original-article-reprinted">The Original Article, Reprinted</a>
</h3>
<p class="big">Myths About Scalable Parallel Programming Languages:<br>
Part 1: Productivity and Performance</p>
<p>I work on a language designed for scalable computing named Chapel.
For readers unfamiliar with it, Chapel is an emerging parallel
programming language whose design and development are being led by <span class="sidenote"><label class="sidenote-label" for="sidenote-1">Cray Inc.</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-1"></input><span class="sidenote-content sidenote-right" style="margin-top: -4.5rem"><span class="sidenote-delimiter">[note:</span>(and now by Hewlett Packard
Enterprise)<span class="sidenote-delimiter">]</span></span></span> (<a href="https://chapel-lang.org"target="_blank" rel="noopener">https://chapel-lang.org</a>) as part of the
<a href="https://www.nitrd.gov/nitrdgroups/images/a/a2/High_Productivity_Computing_Systemsl_DARPA.pdf"target="_blank" rel="noopener">DARPA High Productivity Computing Systems program
(HPCS)</a>.</p>
<p>Chapel has the goal of improving the productivity of parallel
programmers, particularly those interested in large-scale computing.
Much has been written previously about Chapel’s motivations, themes,
features, and history [1, 2, 3], including descriptions of some of its
more advanced concepts [4, 5].  For those hearing about Chapel for the
first time but not ready to track down previous work, some terms to
give you a feel for its design include: “general-purpose parallelism”,
“open-source”, “portable”, &ldquo;<span class="sidenote"><label class="sidenote-label" for="sidenote-2">dynamic</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-2"></input><span class="sidenote-content sidenote-right" style="margin-top: -9.5rem"><span class="sidenote-delimiter">[note:</span>I
can't quite recall why I chose this adjective, as it's not one I would
naturally reach for today.  My best guess is that I meant that Chapel
supports dynamic parallelism—the arbitrary creation of new tasks by
other tasks.  However, it seems like I could've made that clearer to
avoid potential confusion with "dynamically typed", which Chapel is
not.<span class="sidenote-delimiter">]</span></span></span>&rdquo;, “locality-aware”, “elegant”,
“work-in-progress”, “customizable”, “multiresolution”, and (keeping in
mind that I’m biased) &ldquo;<span class="sidenote"><label class="sidenote-label" for="sidenote-3">it rocks!</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-3"></input><span class="sidenote-content sidenote-right" style="margin-top: 7.5rem"><span class="sidenote-delimiter">[note:</span>The
article I originally submitted ended this list with "kick-ass."
instead, but my editors seemed to think that this might be too profane
for IEEE.  For similar reasons, we ended up dropping some hip-hop
lyrics that I originally used to kick off the article (the lyrics
themselves were not profane, but others in the song were).  <span class="sidenote-delimiter">]</span></span></span>&rdquo;</p>
<p>Because most computer scientists use programming languages of one form
or another, we tend to have strong opinions about them: we complain
about the languages we hate; we vacillate between championing and
complaining about the ones we like; and we argue endlessly about why
every new language is doomed to failure.  Despite this general
atmosphere of pessimism around new languages, many of us have a desire
to move beyond today’s hodge-podge of parallel languages and
notations.  Sometimes this is motivated by a lack in productivity or
capability; other times by the challenges posed by next-generation
processor architectures; sometimes we just want parallel programming
to be as nice as desktop programming. But whatever the reasons, and
however long the odds, we feel there is a need to continue striving to
improve the state of the art in scalable parallel languages.</p>
<p>In this series of blog articles (of which this is the first), rather
than rehash aspects of Chapel that are well-covered elsewhere, I
thought I’d cover some of the myths about scalable parallel
programming languages that our team frequently encounters and counter
them based on our experiences with Chapel and other parallel
languages.</p>
<h4 id="myth-1-productivity-is-at-odds-with-performance">
  <a href="#myth-1-productivity-is-at-odds-with-performance">Myth #1: Productivity is at odds with performance</a>
</h4>
<p>When most people hear that we are working on a language designed with
productivity as its goal, they assume that performance will be
sacrificed—that raising the level of abstraction will necessarily hurt
performance.  And there certainly is precedent for this opinion.</p>
<p>For starters, the very wording of this statement bothers me because it
suggests that the term “productivity” somehow does not encompass
performance.  If we think of productivity as being related to “time to
solution” (or “solutions”), then for most use cases, performance
really needs to be part of the definition.  In the specific case of
Chapel, the HPCS program at its outset defined productivity to include
performance, combined with programmability, portability, and
robustness.  To that end, in designing Chapel, we worked very hard to
select high-level features that we believed would help performance, or
at least not hurt it.  (Full disclosure: it should be mentioned that
in many cases, <span class="sidenote"><label class="sidenote-label" for="sidenote-4">today’s Chapel compiler</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-4"></input><span class="sidenote-content sidenote-right" style="margin-top: -14.5rem"><span class="sidenote-delimiter">[note:</span>
Happily, the performance generated by the Chapel compiler today is in
<i>much</i> better shape than when this article was originally
published.  Chapel frequently <a href =
"https://chapel-lang.org/fast/">competes with</a> typical C, C++, and
Fortran programs; it has <a href =
"https://chapel-lang.org/scalable/">scaled</a> to thousands of compute
nodes, millions of cores, and over a thousand GPUs; and it has even
out-scaled MPI and SHMEM for specific parallel computations and
architectures.  Importantly, all of these results have relied on its <a
href = "https://chapel-lang.org/productive/">productive features</a>.
All that said, there is still plenty of room for further improvement,
particularly as hardware itself is always improving and changing. <span class="sidenote-delimiter">]</span></span></span> does not yet produce the performance that it was
designed to; recall the “work-in-progress” mention above).</p>
<blockquote class="pull-quote">
    <div class="quote-wrapper">
        <div class="quote-container"><span class="open-quote">“</span></div>
            <div class="quote-content">
                <p>

The more clearly a programmer’s intentions can be described in a
language, the more semantic information the compiler has available
when optimizing the code

</p>
            </div>
        <div class="quote-container"><span class="close-quote">”</span></div>
    </div>
    
</blockquote>

<p>Consider that one of the main goals of a programming language is to
permit users to communicate algorithms to a compiler (or interpreter)
such that they can be implemented on the target hardware, correctly
and efficiently.  This means that the more clearly a programmer’s
intentions can be described in a language, the more <span class="sidenote"><label class="sidenote-label" for="sidenote-5">semantic information the compiler has available when optimizing the code</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-5"></input><span class="sidenote-content sidenote-left"><span class="sidenote-delimiter">[note:</span>Stay
tuned... We'll call out examples of such optimizations that we've
implemented in Chapel since the original article was written in the
discussion section at the end.<span class="sidenote-delimiter">]</span></span></span>.  For that reason, a
productivity-oriented language designer should select concepts and
abstractions that will aid the compiler’s analysis and optimization
(or at least do no harm), rather than ones that would handicap it.</p>
<h6 id="enabling-optimization-through-improved-abstractions">
  <a href="#enabling-optimization-through-improved-abstractions">Enabling optimization through improved abstractions</a>
</h6>
<p>As an example, consider sparse matrix computations, such as the very
simple operation of assigning a sparse matrix to a dense one.  As a
compiler writer, there are a number of interesting optimizations that
I can apply to such operations—such as using <em>loop splitting</em> to
specialize zippered operations like this assignment—to take advantage
of the semantic knowledge that large portions of the iteration space
will contain identical (“zero”) values.  Yet if the compiler doesn’t
know about the sparse arrays, it cannot apply these optimizations.</p>
<p>Consider implementing the sparse matrix of this example using the
<a href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_%28CSR,_CRS_or_Yale_format%29"target="_blank" rel="noopener">Compressed Sparse
Row</a>
storage format.  When using C or Fortran, programmers will typically
use 1D arrays to store the nonzero values, column indices, and row
start values.  They will also typically index into these arrays using
values stored in the other ones.  This is a pattern known as <em>indirect
indexing</em>, and it poses significant challenges to compiler
optimization.  By using these low-level concepts, the programmer has
failed to express important semantic information about the array
values that could be used to optimize the scalar code—such as the fact
that the row start indices will refer to disjoint subsets of the
column index and value arrays.  Worse, the code fails to impart to the
compiler—not to mention human readers—any clear indication that a
sparse array is being used.</p>
<details>
    <summary><strong>(What does CSR and indirect indexing look like?)</strong></summary>

    <div style="padding-left: 2vw; padding-right: 2vw; padding-bottom: 2ch;">
        <p>I must have been taking my word-count budget very literally when
writing this original article because I think the above paragraph
screams for a code illustration.  Here&rsquo;s how a typical CSR
implementation might be represented, using Chapel syntax:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="kd">config</span><span class="w"> </span><span class="kd">const</span><span class="w"> </span><span class="nx">numRows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.,</span><span class="w">       </span><span class="c1">// the logical number of rows in the matrix
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">             </span><span class="nx">numCols</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.,</span><span class="w">       </span><span class="c1">// the logical number of columns
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">             </span><span class="nx">numNonzeroes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.;</span><span class="w">  </span><span class="c1">// the total number of non-zero entries
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">config</span><span class="w"> </span><span class="kd">type</span><span class="w"> </span><span class="nx">eltType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">real</span><span class="p">;</span><span class="w">       </span><span class="c1">// the type of the non-zero entries
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">// a dense vector storing the non-zero matrix elements
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">var</span><span class="w"> </span><span class="nx">nonzeroes</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="nx">numNonzeroes</span><span class="p">]</span><span class="w"> </span><span class="nx">eltType</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">const</span><span class="w"> </span><span class="nx">rowStart</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="nx">numRows</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.,</span><span class="w">   </span><span class="c1">// the index where each row starts
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">      </span><span class="nx">colIdx</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="o">..</span><span class="nx">numNonzeroes</span><span class="p">]</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.;</span><span class="w">  </span><span class="c1">// the column index of each nonzero
</span></span></span></code></pre></div><p>And here&rsquo;s how a typical serial loop over the data structure might
look, say to set all of the non-zero elements to a function of their
row and column indices:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="k">for</span><span class="w"> </span><span class="nx">r</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="mi">1</span><span class="o">..</span><span class="nx">numRows</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">rowStart</span><span class="p">[</span><span class="nx">r</span><span class="p">]</span><span class="o">..&lt;</span><span class="nx">rowStart</span><span class="p">[</span><span class="nx">r</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nx">nonzeroes</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">r</span><span class="o">*</span><span class="mi">1000</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">colIdx</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span><span class="w">
</span></span></span></code></pre></div><p>The indirect indexing that the original article mentions appears in
this example by virtue of the fact that the <code>i</code> index used to access
the <code>nonzeroes</code> and <code>colIdx</code> arrays comes from an array itself, making
it difficult, if not impossible, for a compiler to reason about.</p>
<p>That said, reading this article 13 years later, my inner critic notes
that languages that support explicit parallelism can still help the
compiler accelerate the code even without it having an understanding
of the relationship between <code>rowStart</code>, <code>nonzeroes</code>, and <code>colIdx</code>.
Specifically, writing the loop nest above using parallel loops doesn&rsquo;t
tell the compiler that the <code>i</code> loops will be consecutive and disjoint,
but it does indicate that they can and should be executed in parallel:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="k">forall</span><span class="w"> </span><span class="nx">r</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="mi">1</span><span class="o">..</span><span class="nx">numRows</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">forall</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">rowStart</span><span class="p">[</span><span class="nx">r</span><span class="p">]</span><span class="o">..&lt;</span><span class="nx">rowStart</span><span class="p">[</span><span class="nx">r</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nx">nonzeroes</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">r</span><span class="o">*</span><span class="mi">1000</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">colIdx</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span><span class="w">
</span></span></span></code></pre></div><p>At the same time, I still strongly believe that an explicit
representation of sparsity in a language improves productivity, as
we&rsquo;ll see in the next details section.</p>

    </div>
</details>

<p>A C++ or Java programmer would probably take the raw arrays and loop
patterns above and wrap them in a class in order to abstract the
underlying data structures away from their uses, providing a cleaner
interface for accessing and iterating over the sparse array.  With
good naming choices, this OOP-based approach can go a long way toward
making the code more programmable and comprehensible to a human
reader.  Yet for the compiler, it does little to help, and often
hurts, by adding more code framework to sort through in analyzing the
computation (including the potential for dynamic dispatch issues if
the class is part of a larger matrix class hierarchy).  Such examples
of higher-level programming are arguably a large part of why the HPC
community tends to conflate productivity with poor performance.</p>
<blockquote class="pull-quote">
    <div class="quote-wrapper">
        <div class="quote-container"><span class="open-quote">“</span></div>
            <div class="quote-content">
                <p>

The end-user gets improved programmability while the compiler gets
more semantic information to use in performance optimizations—a
win-win situation.

</p>
            </div>
        <div class="quote-container"><span class="close-quote">”</span></div>
    </div>
    
</blockquote>

<p>Now, imagine a language that supports sparse matrices or arrays
directly, like Matlab, ZPL, or Chapel.  Such languages provide similar
productivity benefits to the user as the OOP approach, and often
improve upon it, due to the opportunity to support a specialized
syntax.  They also hand the compiler a nice piece of semantic
information: <em>This array has a nontrivial number of identical entries.</em>
As a result, your favorite compiler team can shift their focus from
heroically wrestling with optimizing indirect indices and unraveling
method calls toward issues that are more closely related to the
semantics that the programmer wanted to express anyway.  Thus, the
end-user gets improved programmability while the compiler gets more
semantic information to use in performance optimizations—a win-win
situation.</p>
<details>
    <summary><strong>(What do Chapel&rsquo;s sparse features look like?)</strong></summary>

    <div style="padding-left: 2vw; padding-right: 2vw; padding-bottom: 2ch;">
        <p>Here is the computation from the previous details section written
using Chapel&rsquo;s sparse features:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="kd">config</span><span class="w"> </span><span class="kd">const</span><span class="w"> </span><span class="nx">numRows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.,</span><span class="w">       </span><span class="c1">// the logical number of rows in the matrix
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">             </span><span class="nx">numCols</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.,</span><span class="w">       </span><span class="c1">// the logical number of columns
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">             </span><span class="nx">numNonzeroes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.;</span><span class="w">  </span><span class="c1">// the total number of non-zero entries
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">config</span><span class="w"> </span><span class="kd">type</span><span class="w"> </span><span class="nx">eltType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">real</span><span class="p">;</span><span class="w">       </span><span class="c1">// the type of the non-zero entries
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">// the logical and sparse indices representing the matrix
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">const</span><span class="w"> </span><span class="nx">Dom</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="o">..</span><span class="nx">numRows</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">..</span><span class="nx">numCols</span><span class="p">},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nx">SpsDom</span><span class="p">:</span><span class="w"> </span><span class="k">sparse</span><span class="w"> </span><span class="k">subdomain</span><span class="p">(</span><span class="nx">Dom</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">..</span><span class="p">.;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">var</span><span class="w"> </span><span class="nx">SpsMat</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="nx">SpsDom</span><span class="p">]</span><span class="w"> </span><span class="nx">eltType</span><span class="p">;</span><span class="w">  </span><span class="c1">// the sparse matrix itself
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">forall</span><span class="w"> </span><span class="p">(</span><span class="nx">r</span><span class="p">,</span><span class="nx">c</span><span class="p">)</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">SpsDom</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nx">SpsMat</span><span class="p">[</span><span class="nx">r</span><span class="p">,</span><span class="nx">c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">r</span><span class="o">*</span><span class="mi">1000</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">c</span><span class="p">;</span><span class="w">
</span></span></span></code></pre></div>
    </div>
</details>

<h6 id="performance-neutral-productivity-features">
  <a href="#performance-neutral-productivity-features">Performance-Neutral Productivity Features</a>
</h6>
<p>In other cases, productivity features can be completely neutral with
respect to execution performance.  As an example, Chapel supports
static type inference, which permits users to optionally elide the
types of variables, as well as function arguments and return types.
The compiler analyzes the program to determine the types in such
cases.  This feature permits programmers to prototype algorithms more
quickly, while also making them more flexible with respect to type
changes over time.  As an example, the following two Chapel programs
are equivalent:</p>
<p><strong>Listing 1: Inferred types</strong></p>











<div data-code-type="main" data-code-section="">
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="k">proc</span><span class="w"> </span><span class="nf">square</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="nx">x</span><span class="o">*</span><span class="nx">x</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">const</span><span class="w"> </span><span class="nx">pi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">3.1415</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nx">pi2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">square</span><span class="p">(</span><span class="nx">pi</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div>
</div>

<p><strong>Listing 2: Specified types</strong></p>











<div data-code-type="main" data-code-section="">
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="k">proc</span><span class="w"> </span><span class="nf">square</span><span class="p">(</span><span class="nx">x</span><span class="p">:</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="mi">64</span><span class="p">)):</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="nx">x</span><span class="o">*</span><span class="nx">x</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">const</span><span class="w"> </span><span class="nx">pi</span><span class="p">:</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">3.1415</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nx">pi2</span><span class="p">:</span><span class="w"> </span><span class="kt">real</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">square</span><span class="p">(</span><span class="nx">pi</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div>
</div>

<p>Depending on personal preference, you might consider either code to be
more productive than the other.  The code in Listing 1 is arguably
easier to write, but could be considered more difficult to read since
the declarations don’t explicitly name their types.  As a result, a
human reader must perform the same inference steps that the compiler
would in order to determine that <code>pi</code> and <code>pi2</code> are <code>real</code> floating
point values, and that <code>square()</code> takes and returns <code>real</code> values (for
this callsite, anyway).  Meanwhile, the version in Listing 2 makes the
types clearer, but would require more work to change if the user
wanted to move from 64-bit <code>real</code>s to a different bit-width or type
(such as complex values).</p>
<p>Users may initially fear that the inferred types of Listing 1 make it
expensive. The type-free code resembles a scripting language,
suggesting that Chapel might use dynamic types with their
corresponding execution-time overheads.  But each Chapel variable has
a single fixed type for its lifetime, which is determined at
compile-time.  This means there is no execution-time overhead compared
to the version in Listing 2 or a traditional compiled language like C
or Fortran.</p>
<p>Many other Chapel features have similar productivity benefits without
imposing execution-time costs, such as its support for inlined
iterator functions.  Such features make code authoring and maintenance
far more productive and flexible without resulting in an
implementation that differs from what a programmer would get in a
traditional language.</p>
<p>This leads us to our conclusion:</p>
<h5 id="counterpoint-1-a-smart-selection-of-language-features-can-improve-programmer-productivity-while-also-having-positive-or-neutral-impacts-on-performance">
  <a href="#counterpoint-1-a-smart-selection-of-language-features-can-improve-programmer-productivity-while-also-having-positive-or-neutral-impacts-on-performance">Counterpoint #1: A smart selection of language features can improve programmer productivity while also having positive or neutral impacts on performance.</a>
</h5>
<p>Tune in next time for more myths about scalable parallel programming languages.</p>
<h4 id="references">
  <a href="#references">References</a>
</h4>
<p>[1] B. L. Chamberlain, D. Callahan, H. P. Zima, <a href="http://hpc.sagepub.com/content/21/3/291.abstract"target="_blank" rel="noopener">Parallel
Programmability and the Chapel
Language</a>,
<em>International Journal of High Performance Computing Applications</em>,
August 2007, 21(3): 291–312.</p>
<p>[2] Chapel Team, Cray Inc., <a href="https://chapel-lang.org/spec/spec-0.91.pdf"target="_blank" rel="noopener">Chapel Language Specification (version
0.91)</a>, <span class="sidenote"><label class="sidenote-label" for="sidenote-6">April 19, 2012</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-6"></input><span class="sidenote-content sidenote-right"><span class="sidenote-delimiter">[note:</span>A current version of the language spec can
be found <a href =
"https://chapel-lang.org/docs/language/spec/">here</a><span class="sidenote-delimiter">]</span></span></span>.</p>
<p>[3] B. L. Chamberlain, <a href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-09766-4_54"target="_blank" rel="noopener">Chapel (Cray Inc. HPCS
Language)</a>,
<em>Encyclopedia of Parallel Computing</em>, David Padua (editor), pp. 249–256,
Springer US, 2011.</p>
<p>[4] B. L. Chamberlain, S.-E. Choi, S. J. Deitz, A. Navarro,
<a href="http://pgas11.rice.edu/papers/ChamberlainEtAl-Chapel-Iterators-PGAS11.pdf"target="_blank" rel="noopener">User-Defined Parallel Zippered Iterators in
Chapel</a>,
<em>PGAS 2011: Fifth Conference on Partitioned Global Address Space
Programming Models</em>, October 2011.</p>
<p>[5] B. L. Chamberlain, S.-E. Choi, S. J. Deitz, D. Iten, V. Litvinov,
<a href="https://chapel-lang.org/publications/cug11-final.pdf"target="_blank" rel="noopener">Authoring User-Defined Domain Maps in
Chapel</a>, <em>CUG
2011</em>, May 2011.</p>
<h4 id="acknowledgments">
  <a href="#acknowledgments">Acknowledgments</a>
</h4>
<p>Thanks to the members of the Chapel team, past and present, for the
many interesting discussions that have helped inform this article’s
contents.  This material is based upon work supported by the Defense
Advanced Research Projects Agency under its Agreement
No. HR0011-07-9-0001. Any opinions, findings and conclusions or
recommendations expressed in this material are those of the author and
do not necessarily reflect the views of the Defense Advanced Research
Projects Agency.</p>
<hr>
<h3 id="reflections-on-the-original-article">
  <a href="#reflections-on-the-original-article">Reflections on the Original Article</a>
</h3>
<p>By and large, I think that the premise of this first article in the
&ldquo;10 myths&rdquo; series holds up.  I definitely still believe that
thoughtful, intelligent curation of features can result in a
programming language that is easier for humans to read and write,
while also enabling good performance and simplifying performance
optimizations.</p>
<h4 id="the-sparse-example">
  <a href="#the-sparse-example">The Sparse Example</a>
</h4>
<p>Ironically, despite this article&rsquo;s partial focus on optimizing sparse
matrix computations, that set of features has not received as much
attention in Chapel&rsquo;s implementation and optimization efforts as I had
probably been anticipating they would in 2012.  Specifically, some of
our key focus areas since then have been on improving traditional
sequential language features such as OOP, optimizing performance and
scalability for dense computations, targeting GPUs, and modernizing
our compiler.  Meanwhile the sparse subset of the language has largely
been neglected.  However, I was happy to have the opportunity to make
some improvements to the sparse support <a href="https://chapel-lang.org/blog/posts/announcing-chapel-2.3/#sparse-computations"target="_blank" rel="noopener">in the past
year</a>,
and hope to do more going forward.</p>
<p>Curious about the status of the specific example of sparse-to-dense
assignment mentioned in the article, I found that while we do not
support this pattern today, I was able to add support for it in a
subroutine whose body is two lines of Chapel code as:</p>











<div data-code-type="main" data-code-section="">
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">63
</span><span class="lnt">64
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="w">    </span><span class="k">forall</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">a</span><span class="p">.</span><span class="k">domain</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nx">a</span><span class="p">[</span><span class="nx">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">b</span><span class="p">[</span><span class="nx">idx</span><span class="p">];</span></span></span></code></pre></td></tr></table>
</div>
</div>
</div>

<p>Then, to implement the loop-splitting optimization mentioned above, I
changed it into the following pair of lines that assigns <code>A</code> the <span class="sidenote"><label class="sidenote-label" for="sidenote-7">&ldquo;zero&rdquo;</label><input class="sidenote-checkbox" type="checkbox" id="sidenote-7"></input><span class="sidenote-content sidenote-right"><span class="sidenote-delimiter">[note:</span>Chapel's sparse matrices support
arbitrary "zero" values, so we call this value the <i>IRV</i>, or
<i>implicitly replicated value</i> for short in Chapel to avoid any
implication that it needs to have the value "0".<span class="sidenote-delimiter">]</span></span></span>
values first, followed by a loop that only copies over the non-zero
elements:</p>











<div data-code-type="main" data-code-section="">
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-chapel" data-lang="chapel"><span class="line"><span class="cl"><span class="w">    </span><span class="nx">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="nx">IRV</span><span class="p">;</span><span class="w">                 </span><span class="c1">// assign B&#39;s &#34;zero&#34; value to all of A,
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="k">forall</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="k">domain</span><span class="w"> </span><span class="k">do</span><span class="w">  </span><span class="c1">// then copy over the non-zero elements
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">      </span><span class="nx">a</span><span class="p">[</span><span class="nx">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">b</span><span class="p">[</span><span class="nx">idx</span><span class="p">];</span></span></span></code></pre></td></tr></table>
</div>
</div>
</div>

<p>This rewrite has the benefit of avoiding <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> sparse random access
operations, which are expensive by nature.  On my M1 Mac, this
resulted in a ~3x improvement when assigning a 100,000 x 100,000
tridiagonal sparse matrix and a ~24x improvement for a 10,000 x 10,000
case.  Now I need to follow up by opening a PR that adds this as an
official assignment operator between sparse and dense arrays.  In the
meantime, my full code can be seen here:</p>




<div class="file" data-code-type="main">
    <details>
        <summary class="file-header">
            <a href=code/assign-sparse-to-dense.chpl download="assign-sparse-to-dense.chpl">assign-sparse-to-dense.chpl</a>
            
        </summary>
        
        <div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-chpl" data-lang="chpl"><span class="line"><span class="cl"><span class="k">use</span><span class="w"> </span><span class="nx">Time</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">config</span><span class="w"> </span><span class="kd">param</span><span class="w"> </span><span class="nx">optimizeAssign</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span><span class="p">;</span><span class="w">  </span><span class="c1">// use the optimized form?
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">config</span><span class="w"> </span><span class="kd">const</span><span class="w"> </span><span class="nx">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w">                  </span><span class="c1">// the matrix problem size
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">config</span><span class="w"> </span><span class="kd">const</span><span class="w"> </span><span class="nx">printArrays</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">      </span><span class="c1">// whether to print the arrays or timings
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">             </span><span class="nx">printTiming</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// a dense and sparse n x n domain (index set)
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">const</span><span class="w"> </span><span class="nx">D</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="o">..</span><span class="nx">n</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">..</span><span class="nx">n</span><span class="p">},</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nx">SD</span><span class="p">:</span><span class="w"> </span><span class="k">sparse</span><span class="w"> </span><span class="k">subdomain</span><span class="p">(</span><span class="nx">D</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">genTridiagInds</span><span class="p">(</span><span class="nx">n</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// a dense and sparse n x n array, initialized to 1.0 and 2.0, respectively
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">var</span><span class="w"> </span><span class="nx">AD</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="nx">D</span><span class="p">]</span><span class="w"> </span><span class="kt">real</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nx">AS</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="nx">SD</span><span class="p">]</span><span class="w"> </span><span class="kt">real</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">if</span><span class="w"> </span><span class="nx">printArrays</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nx">writeln</span><span class="p">(</span><span class="nx">AD</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nx">writeln</span><span class="p">(</span><span class="nx">AS</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// time the assignment between the arrays
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">var</span><span class="w"> </span><span class="nx">s</span><span class="p">:</span><span class="w"> </span><span class="nx">stopwatch</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nx">s</span><span class="p">.</span><span class="nx">start</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nx">assign</span><span class="p">(</span><span class="nx">AD</span><span class="p">,</span><span class="w"> </span><span class="nx">AS</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nx">s</span><span class="p">.</span><span class="nx">stop</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// print the resulting array and timing information
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">if</span><span class="w"> </span><span class="nx">printArrays</span><span class="w"> </span><span class="k">then</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nx">writeln</span><span class="p">(</span><span class="nx">AD</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">if</span><span class="w"> </span><span class="nx">printTiming</span><span class="w"> </span><span class="k">then</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nx">writeln</span><span class="p">(</span><span class="s">&#34;Assignment time = &#34;</span><span class="p">,</span><span class="w"> </span><span class="nx">s</span><span class="p">.</span><span class="nx">elapsed</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// validate that the assignment was correct
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">forall</span><span class="w"> </span><span class="p">(</span><span class="nx">i</span><span class="p">,</span><span class="nx">j</span><span class="p">)</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">D</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="nx">j</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="nx">i</span><span class="o">-</span><span class="mi">1</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nx">j</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="nx">i</span><span class="o">+</span><span class="mi">1</span><span class="w"> </span><span class="k">then</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nx">assert</span><span class="p">(</span><span class="nx">AD</span><span class="p">[</span><span class="nx">i</span><span class="p">,</span><span class="nx">j</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">2.0</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">else</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nx">assert</span><span class="p">(</span><span class="nx">AD</span><span class="p">[</span><span class="nx">i</span><span class="p">,</span><span class="nx">j</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">0.0</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nx">writeln</span><span class="p">(</span><span class="s">&#34;Verification passed&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// Assign from a sparse to a dense array.  Note that this should
</span></span></span><span class="line"><span class="cl"><span class="c1">// really be an &#39;operator =&#39; definition, but the compiler currently
</span></span></span><span class="line"><span class="cl"><span class="c1">// prevents users from defining these in their modules; it works if
</span></span></span><span class="line"><span class="cl"><span class="c1">// added to one of Chapel&#39;s internal or standard modules.
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">proc</span><span class="w"> </span><span class="nf">assign</span><span class="p">(</span><span class="kd">ref</span><span class="w"> </span><span class="nx">a</span><span class="p">:</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="nx">b</span><span class="p">:</span><span class="w"> </span><span class="p">[])</span><span class="w"> </span><span class="k">where</span><span class="w"> </span><span class="o">!</span><span class="nx">a</span><span class="p">.</span><span class="nx">isSparse</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="nx">isSparse</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="o">!</span><span class="nx">optimizeAssign</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">forall</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">a</span><span class="p">.</span><span class="k">domain</span><span class="w"> </span><span class="k">do</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nx">a</span><span class="p">[</span><span class="nx">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">b</span><span class="p">[</span><span class="nx">idx</span><span class="p">];</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nx">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="nx">IRV</span><span class="p">;</span><span class="w">                 </span><span class="c1">// assign B&#39;s &#34;zero&#34; value to all of A,
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">    </span><span class="k">forall</span><span class="w"> </span><span class="nx">idx</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="nx">b</span><span class="p">.</span><span class="k">domain</span><span class="w"> </span><span class="k">do</span><span class="w">  </span><span class="c1">// then copy over the non-zero elements
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="w">      </span><span class="nx">a</span><span class="p">[</span><span class="nx">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">b</span><span class="p">[</span><span class="nx">idx</span><span class="p">];</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1">// generate the indices for a tridiagonal matrix of size n
</span></span></span><span class="line"><span class="cl"><span class="c1">//
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">iter</span><span class="w"> </span><span class="nf">genTridiagInds</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="kd">in</span><span class="w"> </span><span class="mi">1</span><span class="o">..</span><span class="nx">n</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">then</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="k">yield</span><span class="w"> </span><span class="p">(</span><span class="nx">i</span><span class="p">,</span><span class="nx">i</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">yield</span><span class="w"> </span><span class="p">(</span><span class="nx">i</span><span class="p">,</span><span class="nx">i</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nx">n</span><span class="w"> </span><span class="k">then</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="k">yield</span><span class="w"> </span><span class="p">(</span><span class="nx">i</span><span class="p">,</span><span class="nx">i</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div>
    </details>
</div>

<p>Despite our lack of focus on sparse computations since the original
article, we <em>have</em> implemented several other compiler optimizations in
the intervening years that have benefited from Chapel&rsquo;s high-level
representation of things like parallelism and index sets.  Key
examples include a compiler optimization for unordered/asynchronous
operations within <code>forall</code> loops (see &lsquo;Unordered Compiler
Optimizations&rsquo; in <a href="https://chapel-lang.org/releaseNotes/1.19/05-benchmark-opts.pdf"target="_blank" rel="noopener">the release notes for Chapel
1.19</a>)
and <a href="https://link.springer.com/chapter/10.1007/978-3-030-99372-6_1"target="_blank" rel="noopener">a pair of
optimizations</a>
for reducing overheads when computing with distributed arrays.</p>
<h4 id="the-type-inference-example">
  <a href="#the-type-inference-example">The Type Inference Example</a>
</h4>
<p>I was pleased to find that the examples demonstrating type inference
from the original article continue to work today without changes,
though I was somewhat amused by my imprecise representation of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span>.
Re-reading today, I do wonder how many modern programmers would find
the explicitly-typed version &ldquo;clearer&rdquo;, as I suggested back then,
particularly given the continued growth in popularity of Python and
uptake of <code>auto</code> declarations in C++.  In retrospect, maybe I
should&rsquo;ve used other characterizations of why it might be considered
more productive, like being more precise or less prone to errors.  For
example, <code>square(&quot;pi&quot;);</code> would have unintended consequences in the
type-inferred case, since <code>*</code> isn&rsquo;t supported between strings by
default.</p>
<p>In retrospect, it also seems a bit pedantic that I used <code>real(64)</code> as
the type in the explicit version rather than <code>real</code>, which is defined
to be 64 bits in Chapel—almost like I was trying to go out of my way
to make it more verbose.  That said, I can also think of users who
tend to prefer that additional level of explicitness in their code.</p>
<h4 id="wrapping-up">
  <a href="#wrapping-up">Wrapping Up</a>
</h4>
<p>All in all, I think the premise of the original article holds up and
that, by and large, the features we had designed for Chapel in 2012
have largely stood the test of time in terms of providing the
programmability and support for performance and optimization that we
intended.  Specifically, <a href="../../series/7-questions-for-chapel-users/">users have indicated their appreciation of
many of Chapel&rsquo;s features</a>, and I have a hard time
thinking of any of its unique ones that feel inherently problematic
from the perspective of obtaining performance.</p>
<p>Tune in next month when we&rsquo;ll revisit the second article in this
series, which wrestles with the question of what past parallel
language failures imply for future attempts.</p>

</div>

        </main>
<div class="container">
    <div class="share-view">
        <h3>Share this article:</h3>
        <div class="share-buttons">
        
        
        
        <a style="--button-color: #6cb0f9; --button-color-light: white;" class="button share-button" href="https://bsky.app/intent/compose?text=Check&#43;out&#43;this&#43;post&#43;entitled&#43;%2210&#43;Myths&#43;About&#43;Scalable&#43;Parallel&#43;Programming&#43;Languages&#43;%28Redux%29%2C&#43;&#43;Part&#43;1%3A&#43;Productivity&#43;and&#43;Performance%22&#43;on&#43;the&#43;Chapel&#43;Programming&#43;Language&#43;blog%3A&#43;https%3A%2F%2Fchapel-lang.org%2Fblog%2Fposts%2F10myths-part1%2F" target="_blank" rel="noopener noreferrer">
    <img width="30" height="30" src="../../img/bluesky-logo.jpg" alt="Share on BlueSky">
</a>

        <a style="--button-color: #3a559f; --button-color-light: white;" class="button share-button" href="https://www.facebook.com/sharer/sharer.php?description=Check&#43;out&#43;this&#43;post&#43;entitled&#43;%2210&#43;Myths&#43;About&#43;Scalable&#43;Parallel&#43;Programming&#43;Languages&#43;%28Redux%29%2C&#43;&#43;Part&#43;1%3A&#43;Productivity&#43;and&#43;Performance%22&#43;on&#43;the&#43;Chapel&#43;Programming&#43;Language&#43;blog%3A&amp;u=https%3A%2F%2Fchapel-lang.org%2Fblog%2Fposts%2F10myths-part1%2F" target="_blank" rel="noopener noreferrer">
    <img width="30" height="30" src="../../img/facebook-logo.png" alt="Share on Facebook">
</a>

        <a style="--button-color: #2867b2; --button-color-light: white;" class="button share-button" href="https://linkedin.com/share?text=Check&#43;out&#43;this&#43;post&#43;entitled&#43;%2210&#43;Myths&#43;About&#43;Scalable&#43;Parallel&#43;Programming&#43;Languages&#43;%28Redux%29%2C&#43;&#43;Part&#43;1%3A&#43;Productivity&#43;and&#43;Performance%22&#43;on&#43;the&#43;Chapel&#43;Programming&#43;Language&#43;blog%3A&amp;url=https%3A%2F%2Fchapel-lang.org%2Fblog%2Fposts%2F10myths-part1%2F" target="_blank" rel="noopener noreferrer">
    <img width="30" height="30" src="../../img/linkedin-logo.png" alt="Share on LinkedIn">
</a>

        <a style="--button-color: #ff4500; --button-color-light: white;" class="button share-button" href="https://new.reddit.com/submit?title=10&#43;Myths&#43;About&#43;Scalable&#43;Parallel&#43;Programming&#43;Languages&#43;%28Redux%29%2C&#43;&#43;Part&#43;1%3A&#43;Productivity&#43;and&#43;Performance&amp;url=https%3A%2F%2Fchapel-lang.org%2Fblog%2Fposts%2F10myths-part1%2F" target="_blank" rel="noopener noreferrer">
    <img width="30" height="30" src="../../img/reddit-logo.svg" alt="Share on Reddit">
</a>

        <a style="--button-color: #000000; --button-color-light: #7a7a7a;" class="button share-button" href="http://x.com/share?text=Check&#43;out&#43;this&#43;post&#43;entitled&#43;%2210&#43;Myths&#43;About&#43;Scalable&#43;Parallel&#43;Programming&#43;Languages&#43;%28Redux%29%2C&#43;&#43;Part&#43;1%3A&#43;Productivity&#43;and&#43;Performance%22&#43;on&#43;the&#43;Chapel&#43;Programming&#43;Language&#43;blog%3A&amp;url=https%3A%2F%2Fchapel-lang.org%2Fblog%2Fposts%2F10myths-part1%2F" target="_blank" rel="noopener noreferrer">
    <img width="30" height="30" src="../../img/x-logo.svg" alt="Share on X">
</a>

        </div>
    </div>
</div>


    </body>
</html>
