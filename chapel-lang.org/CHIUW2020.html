<?php
$title="CHIUW 2020: 7th Annual Chapel Implementers and Users Workshop";
?>
<?php include("stdheader.html");?>

<p>&nbsp;</p>

<center>
<h1><big>CHIUW 2020</big></h1>
<h1><small>The 7th Annual</small><br>
Chapel Implementers and Users Workshop<br>
</h1>
<h2>affiliated with <a href = "http://www.ipdps.org/">IPDPS 2020</a> <br>
</h2>

<small>
<a href = "http://www.ipdps.org/"><img width="250" src = "CHIUW/ipdps2020logo.jpg"></a><br>&nbsp;<br>
</small>

<h3>
Friday May 22, 2020<br>
8:30am&ndash;4:30pm PDT (GMT&ndash;7)<br>
free and online via Zoom (due to Covid-19)<br>
</h3>
</center>

<p>
&nbsp;
</p>

<p>
<small><b>Introduction:</b> CHIUW 2020 is the 7th annual <a href =
"CHIUW.html">Chapel Implementers and Users Workshop</a>, organized in
conjunction with <a href =
"http://www.ipdps.org/">IPDPS&nbsp;2020</a>.  CHIUW serves as a forum
where users and developers of the Chapel language&nbsp;(<a href =
"https://chapel-lang.org">chapel-lang.org</a>) can gather to report on
work being done with Chapel, exchange ideas, and forge new
collaborations.  Anyone interested in parallel programming and Chapel
is encouraged to attend CHIUW, from long-term enthusiasts to those
simply curious to learn more.</small>
</p>

<p>
<small><b>Format:</b> Due to Covid-19, CHIUW 2020 will be held online
in a virtual workshop format.  Talks will be given by speakers, either
live or via pre-recorded videos (linked below when available).  Each
talk will be followed by a short question-and-answer session.  Short
breaks between speakers and sessions will be used to deal with any
challenges that come up as a result of the distributed setting.  Due
to the large number of timezones involved, there will not be any
formal meal breaks, but you're encouraged to eat while watching the
talks or during the breaks.
</small>
</p>

<p>
<small><b>Registration:</b> In its online format, CHIUW 2020
is <b>free</b> and open to the public.  Anyone interested in
attending, listening, and participating is welcome to do so as long as
appropriate conduct is observed.  Registering with IPDPS is requested,
though not required, so that they can get an approximate headcount for
the workshop.  Registering will also permit you to access the
online proceedings for IPDPS.  To register, visit the <a href =
"http://www.ipdps.org/">IPDPS home page</a> and click the red
"Register today" button.

</small>
</p>



<p>
&nbsp;
</p>

<table summary = "times and events for CHIUW 2020">

  <tr>
    <td></td><td><center><big><u><b>Program</b></u></big></center></td>
  </tr>

  <tr>
    <td><small><u><b>Time</b> (PDT)</u></small></td><td></td>
  </tr>

  <tr>
    <td></td><td><center><b>Pre-Workshop</b></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>anytime:&nbsp;</small></td> 
    <td><small><a id = "Chapel101"></a><b>Chapel 101</b> [<a href = "CHIUW/2020/CHIUW2020-Chapel101.pdf">slides</a> | <a href = "https://www.youtube.com/watch?v=w9AJZuCJ090">video</a>]</small></td>
  </tr>
  <tr>
    <td></td><td><small><u>Brad Chamberlain</u> (<i>Cray, a Hewlett
    Packard Enterprise Company</i>)</small></td>
  </tr>
  <tr>
    <td></td><td><small>This is a completely optional talk that will
    be posted prior to the official start of the workshop for those
    who are new to Chapel and looking for a crash-course, or for those
    who would simply appreciate a refresher.</small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>


  <tr>
    <td></td><td><center><b>Welcome to CHIUW 2020</b></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>8:30&ndash;9:00:&nbsp;</small></td>
    <td><small><b>Welcome, State of the Project</b> [<a href = "CHIUW/2020/CHIUW2020-Welcome-SoP.pdf">slides</a> | <a href = "https://youtu.be/2EEDyg08jUQ">video</a>]</small></td>
  </tr>
  <tr>
    <td></td><td><small><u>Brad Chamberlain</u> (<i>Cray, a Hewlett Packard Enterprise company</i>)</small></td>
  </tr>
  <tr>
    <td></td><td><small>This session will serve as a welcome to and
        overview of CHIUW 2020, along with a brief summary of
        highlights and milestones achieved within the Chapel project
        since last year.</small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td></td><td><center><b>Break / Technology Check</b></center></td>
  </tr>

  <tr>
    <td valign="top"><small>9:00&ndash;9:15:&nbsp;</small></td> 
    <td><small><b>Break:</b> We'll use this initial, longer break to
    make sure that the streaming technology is generally working for
    people before proceeding.</small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td></td><td><center>
          <b>Chapel Language Evolution</b><br>
        <small>Session chair: Nikhil Padmanabhan (<i>Yale</i>)</small></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>9:15&ndash;9:40&nbsp;</small></td><td><small><b>Towards Stability in the Chapel Language</b> [<a href
    = "CHIUW/2020/Ferguson.pdf">slides</a> | <a href = "https://youtu.be/ih4GLyerkyA">video w/ Q&amp;A</a>]</small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Michael Ferguson</u> (<i>Cray, a Hewlett Packard Enterprise company</i>)
    </small></td>
  </tr>
  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

Language stability is an important upcoming feature of the Chapel
programming language. Chapel users have both requested big changes to
the language and also requested that the language become stable. This
talk will discuss recent efforts to complete the big changes to the
Chapel language so that the language can stabilize.

    </font></small>
    </td>
  </tr>


  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>9:45&ndash;10:10:&nbsp;</small></td><td><small><b>Visibility
    Control: Use and Import Statement Improvements</b>
    [<a href = "CHIUW/2020/Duncan.pdf">slides</a> | <a href = "https://youtu.be/oEz0A6FNngM">video w/ Q&amp;A</a>]
</small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Lydia Duncan</u> (<i>Cray, a Hewlett Packard Enterprise company</i>)
    </small></td>
  </tr>
  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

The Chapel team has recently returned to finalizing our inter-module
interactions, especially regarding use and import statements. This
talk will describe the work that has occurred in this area since
Chapel 1.19.

      </font></small>
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>



  <tr>
    <td></td><td><center><b>Break</b></center></td>
  </tr>

  <tr>
    <td valign="top"><small>10:10&ndash;10:20:&nbsp;</small></td> 
    <td><small><b>Break</b></small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>


  <tr>

    <td></td><td><center><b>Arkouda</b><br>
    <small>Session chair: Brad Chamberlain (<i>Cray/HPE</i>)</small></center>
    
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>


  <tr>
    <td valign="top"><small>10:20&ndash;11:20:&nbsp;</small></td>
    <td><small><a id =
    "keynote"></a><b style="color:DarkGreen">Keynote:</b> <b>Arkouda:
    Chapel-Powered, Interactive Supercomputing for Data Science</b>
    [<a href = "CHIUW/2020/Reus.pdf">slides</a> | <a href =
    "https://youtu.be/g-G_Z_3pgUE">video</a> | <a href = "https://youtu.be/NDNguJd2jss">Q&amp;A</a>]</small></td>
  </tr>
  <tr>
    <td></td>
    <td><small><u>William Reus</u> (<i>U.S. DOD</i>)</small></td>
  </tr>
  <tr>
    <td></td>

    <td><small><b>Abstract:</b> <font color="DarkBlue">

Data science and high-performance computing (HPC) should be a great
match: with datasets growing well beyond the memory of a single node
and computations becoming ever more communication-intensive, the need
for HPC in data science seems clear. And yet, there remains a
frustrating gap between the two disciplines. One major reason is that
data science is an interactive sport&mdash;data scientists
overwhelmingly gravitate towards interactive platforms (e.g. Jupyter
notebooks) and interpreted languages (e.g. Python)&mdash;whereas the
culture of HPC tends to eschew interactivity in favor of compiled
programs and batch jobs. While HPC practitioners prize computational
efficiency, data scientists live by the very different maxim of rapid
hypothesis testing and have demonstrated that they are willing to
ignore HPC technologies entirely rather than give up interactivity.
Bridging this gap entails a change in thinking about the purpose of an
HPC and how it should be used.

</font><p><font color="DarkBlue">

 This talk motivates and demonstrates the interactive use of up to
hundreds of HPC nodes in data science workflows with an open-source
package called Arkouda, which exposes massively parallel, distributed
NumPy-like arrays to a Jupyter notebook running Python&nbsp;3. We have
chosen the NumPy format and Jupyter and Python as front-end
technologies in order to conform to interfaces familiar to data
scientists. Because Arkouda arrays can be constructed from and
exported to NumPy arrays, users can perform heavy computations on
hundreds of HPC nodes and bring back small sets of results for rich
introspection in a single-node Python environment. In the future, we
plan to use this interoperability as a template for bringing existing
HPC codes into an interactive framework, much as NumPy has brought
optimized C and Fortran routines into interactive Python workflows.

</font><p><font color="DarkBlue">

Meanwhile, the computational heart of Arkouda is a relatively
compact yet highly scalable Chapel interpreter that implements a
powerful set of data science primitives. Functionally, this
interpreter comprises a dispatcher, modular data transformations, and
a zero-copy, in-memory object store, all implemented in about 12,000
lines of Chapel. While these components and design principles appear
in other open-source projects, the competitive advantage of Arkouda
comes from the unique position Chapel holds as a productive language
with performance and scaling on par with industry-standard HPC
technologies. For this reason, Arkouda is small enough to be
maintainable while achieving good scaling on communication-intensive
primitives (e.g. argsort) up to at least 512 nodes of a Cray XC.

      </font></small>
    </td>
  </tr>

  <tr>
    <td></td>

    <td><small><b>Bio:</b> <font color="DarkGreen"> 

Dr. Reus is a physical chemist by training, having earned his Ph.D.
from Harvard in the field of molecular electronics. Since graduate
school, he has been cross-training in statistics and parallel
computing in order to apply his scientific expertise to problems in
cyberdefense. Dr. Reus lives near the Chesapeake bay with his wife and
three children.

      </font></small>
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>11:25&ndash;11:50:&nbsp;</small></td><td><small><b>Squeezing Performance out of Arkouda</b>
    [<a href = "CHIUW/2020/Ronaghan.pdf">slides</a> | <a href = "https://youtu.be/W56LYmfnLw0">video w/ Q&amp;A</a>]
</small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Elliot Ronaghan</u> (<i>Cray, a Hewlett Packard Enterprise company</i>)
    </small></td>
  </tr>
  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

This talk will highlight optimizations made to Arkouda, a Python
package backed by Chapel that provides a key subset of the popular
NumPy and Pandas interfaces at HPC scales. Optimizations such as
aggregating communication have significantly improved Arkouda’s
performance across a wide range of architectures. Key optimizations
and benchmark results will be shown on architectures including a
single node server, Ethernet and InfiniBand clusters, and a 512 node
Cray supercomputer.

      </font></small>
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>



  <tr>
    <td></td><td><center><b>Break</b></center></td>
  </tr>

  <tr>
    <td valign="top"><small>11:50&ndash;12:00:&nbsp;</small></td> 
    <td><small><b>Break</b></small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td></td><td><center>
          <b>Applications of Chapel</b><br>
        <small>Session chair: Engin Kayraklioglu (<i>Cray/HPE</i>)</small></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>12:00&ndash;12:25:&nbsp;</small></td>
    <td><small><b>Development of Parallel CFD Applications on Distributed Memory with Chapel</b>
    [<a href = "CHIUW/2020/Parenteau.pdf">slides</a> | <a href = "https://youtu.be/6Lo54Afmi58">video</a> | <a href = "https://youtu.be/cx09jnKpVn0">Q&amp;A</a>]
    </small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Matthieu Parenteau</u>, Simon Bourgault-Cote, Frederic Plante, Eric Laurendeau (<i>Polytechnique Montreal</i>)
    </small></td>
  </tr>

  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

Traditionally, Computational Fluid Dynamics (CFD) software uses
Message Passing Interface (MPI) to handle the parallelism over
distributed memory systems. For a new developer, such as a student or
a new employee, the barrier of entry can be high and more training is
required for each particular software package, which slows down the
research process on actual science. The Chapel programming language
offers an interesting alternative for research and development of CFD
applications.

</font><p><font color="DarkBlue">

In this paper, the developments of two CFD applications are presented:
the first one as an experiment by re-writing a 2D structured flow
solver and the second one as writing from scratch a research 3D
unstructured multi-physics simulation software. Details are given on
both applications with emphasis on the Chapel features which were used
positively in the code design, in particular to improve flexibility
and extend to distributed memory. Some performance pitfalls are
discussed with solutions to avoid them.

</font><p><font color="DarkBlue">

The performance of the unstructured software is then studied and
compared to a traditional open-source CFD software package programmed
in C++ with MPI for communication (SU2). The results show that our
Chapel implementation achieves performances similar to other CFD
software written in C and C++, thus confirming that Chapel is a viable
language for high-performance CFD applications.

      </font></small>
    </td>
  </tr>

  <tr><td>&nbsp;</td></tr>

  <tr>
    <td valign="top"><small>12:30&ndash;12:55:&nbsp;</small></td>
    <td><small><b>Computing Hypergraph Homology in Chapel</b>
    [<a href = "CHIUW/2020/Firoz.pdf">slides</a> | <a href = "https://youtu.be/81ZorrfxDPQ">video w/ Q&amp;A</a>]
    </small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Jesun S. Firoz</u> (<i>Pacific Northwest National
        Laboratory</i>), Louis Jenkins (<i>University of
        Rochester</i>), Cliff Joslyn, Brenda Praggastis, Emilie
        Purvine, Mark Raugas (<i>Pacific Northwest National
        Laboratory</i>)</small>
    </td>
  </tr>
  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

In this paper, we discuss our experience in implementing homology
computation, in particular the Betti number calculations in Chapel
Hypergraph Library (CHGL). Given a dataset represented as a
hypergraph, a Betti number for a particular dimension k indicates how
many k-dimensional ‘voids’ are present in the dataset. Computing the
Betti numbers involve various array-centric and linear algebra
operations. We demonstrate that implementing these operations in
Chapel is both concise and intuitive. In addition, we show that Chapel
provides language constructs for implementing parallel and distributed
execution of the linear algebra kernels with minimal
effort. Syntactically, Chapel provides succinctness of Python, while
delivering comparable and better performance than C++-based and
Julia-based packages for calculating the Betti numbers respectively.

      </font></small>
    </td>
  </tr>

  <tr><td>&nbsp;</td></tr>

  <tr>
    <td valign="top"><small>1:00&ndash;1:15:&nbsp;</small></td>
    <td><small><b>Exploring Chapel Productivity Using Some Graph Algorithms</b>
    [<a href = "CHIUW/2020/Barrett.pdf">slides</a> | <a href = "https://youtu.be/t2Et_3Y0f2E">video w/ Q&amp;A</a>]
    </small></td>
  </tr>
  <tr>
    <td></td><td><small><u>Richard F. Barrett</u>,
        Jeanine Cook,
        Stephen L. Olivier,
        Omar Aaziz,
        Christipher D. Jenkins,
        Courtenay T. Vaughan
        (<i>Sandia National Laboratories</i>)</small></td>
  </tr>

  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

A broad set of data science and engineering questions may be organized
as graphs, providing a powerful means for describing relational
data. Although experts now routinely compute graph algorithms on huge,
unstructured graphs using high performance computing (HPC) or cloud
resources, this practice hasn’t yet broken into the mainstream. Such
computations require great expertise, yet users often need rapid
prototyping and development to quickly customize existing code. Toward
that end, we are exploring the use of the Chapel programming language
as a means of making some important graph analytics more accessible,
examining the breadth of characteristics that would make for a
productive programming environment, one that is expressive,
performant, portable, and robust.

</font><p><font color="DarkBlue">

In this talk we describe our early explorations of this space, based
on miniTri, a miniapp from the Mantevo suite, and the mean hitting
time algorithm, one of the analytics being explored within Grafiki,
both of which are designed for use on distributed memory parallel
processing environments. These implementations have been posed in
terms of key linear algebra operations and algorithms, specifically
sparse matrix-matrix multiplication, operating on integer datatypes,
and the Conjugate Gradient method, based on a graph Laplacian matrix.

      </font></small>
    </td>
  </tr>

  <tr>
    <td valign="top"><small>1:20&ndash;1:45:&nbsp;</small></td>
    <td><small><b>Simulating Ultralight Dark Matter in Chapel</b>
    [<a href = "CHIUW/2020/Padmanabhan.pdf">slides</a> | <a href = "https://youtu.be/OFz-dVnU-fc">video w/ Q&amp;A</a>]
    </small></td>
  </tr>
  <tr>
    <td></td><td><small><u>Nikhil Padmanabhan</u>, (<i>Yale
        University</i>), Elliot Ronaghan (<i>Cray, a Hewlett Packard
        Enterprise Company</i>), J. Luna Zagorac (<i>Yale University</i>),
        Richard Easther (<i>University of Auckland</i>)</small></td>
  </tr>

  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

This talk summarizes the development of a Chapel astrophysics code to
simulate the dynamics of ultralight dark matter. The talk has three
broad goals - (i) to demonstrate that current versions of Chapel can
achieve good performance and scalability for real-world workloads,
(ii) to describe the experience of writing a research code in Chapel,
and (iii) to highlight some of the simulation results we have achieved
using this code. This project originated from a lightning talk at
CHIUW 2019, and is a Chapel-centric update of results at PAW-ATM 2019.

      </font></small>
    </td>
  </tr>


  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td></td><td><center><b>Break</b></center></td>
  </tr>

  <tr>
    <td valign="top"><small>1:45&ndash;1:55:&nbsp;</small></td> 
    <td><small><b>Break</b></small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>



  <tr>
    <td></td><td><center>
          <b>Chapel on GPUs</b><br>
        <small>Session chair: Benjamin Robbins (<i>Cray/HPE</i>)</small></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>1:55&ndash;2:20:&nbsp;</small></td><td><small><b>Exploring a Multi-Resolution GPU Programming Model for Chapel</b>
    [<a href = "CHIUW/2020/Hayashi.pdf">slides</a> | <a href = "https://youtu.be/Mq_vhXlSHxU">video</a> | <a href = "https://youtu.be/rZYBuPMhyuo">Q&amp;A</a>]
</small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Akihiro Hayashi</u>,
        Sri Raj Paul,
        Vivek Sarkar (<i>Georgia Institute of Technology</i>)</small></td>
  </tr>

  <tr>
    <td></td>

    <td><small><b>Abstract:</b> <font color="DarkBlue">

While PGAS (Partitioned Global Address Space) programming models
facilitate productive parallel programming at both the intra-node and
inter-node levels in homogeneous parallel systems, one open question
is better support for accelerators, in particular, GPUs. We believe
Chapel is well suited for this task due to its use of locales and
domains to help abstract away low- level details of data and compute
mappings for different compute nodes, as well as for different
processing units (CPU vs. GPU) within a node. However, the
shortcomings of past approaches on mapping Chapel onto GPUs include 1)
no automatic code generation support for distributed or hybrid
execution of forall loops across multiple CPUs+GPUs nodes and 2) no
appropriate level of abstraction of GPU API (i.e., programmers have to
directly handle raw CUDA/HIP/OpenCL API if the automatic approach does
not work). In this talk, we explore a GPU programming model that
complies with Chapel’s multi-resolution concept, where programmers
have the option of providing a high-level specification and also of
diving into lower-level details to incrementally evolve their
implementations for improved performance on multiple CPUs+GPUs nodes.

      </font></small>
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>2:25&ndash;2:40:&nbsp;</small></td><td><small><b>Chapel on Accelerators</b>
    [<a href = "CHIUW/2020/Ghangas.pdf">slides</a> | <a href = "https://youtu.be/J72IKsGdSVU">video</a> | <a href = "https://youtu.be/U2CPBwtxLr0">Q&amp;A</a>]
</small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Rahul Ghangas</u>,
        Josh Milthorpe
        (<i>The Australian National University</i>)</small></td>
  </tr>

  <tr>
    <td></td>

    <td><small><b>Abstract:</b> <font color="DarkBlue">

This talk introduces the “Chapel on Accelerators” project, which
proposes compiler extensions to provide Chapel's high level constructs
for hardware accelerators, mainly GPGPUs. GPUs form an important part
of scientific computing, from physical simulations to deep learning,
where offloading computation to GPUs can reduce running time by order
of magnitude. The project currently uses static/template OpenCL
kernels to do computation on the GPU. Static kernels are used for well
known expressions, while template kernels are modified at compile time
to support complex expressions. Current support includes offloading of
promoted arithmetic operators and reduce expressions. During the talk,
we discuss the current state of the project, goals and next
steps. Finally, this talk also discusses an experimental idea of the
“GPUArrays” library, which is a purely Chapel based library that
supports offloading of various array operations to the GPU. GPUArrays
uses a lazy evaluation based approach to construct OpenCL kernels by
grouping multiple expressions involving GPUArrays together.

      </font></small>
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td></td><td><center><b>Break</b></center></td>
  </tr>

  <tr>
    <td valign="top"><small>2:40&ndash;2:50:&nbsp;</small></td> 
    <td><small><b>Break</b></small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td></td><td><center>
          <b>Implementing Chapel</b><br>
        <small>Session chair: Ben Albrecht (<i>Cray/HPE</i>)</small></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>2:50&ndash;3:15:&nbsp;</small></td><td><small><b>Paving
    the way for Distributed Non-Blocking Algorithms and Data
    Structures in the Partitioned Global Address Space model</b>
    [<a href = "CHIUW/2020/Dewan.pdf">slides</a> | <a href = "https://youtu.be/Cd5IVbLYPBE">video</a> | <a href = "https://youtu.be/xbLc-oJR59w">Q&amp;A</a>]
</small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Garvit Dewan</u> (<i>Indian Institute of Technology,
        Roorkee</i>), Louis Jenkins (<i>University of Rochester</i>)
    </small></td>
  </tr>
  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

The partitioned global address space memory model has bridged the gap
between shared and distributed memory, and with this bridge comes the
ability to adapt shared memory concepts, such as non-blocking
programming, to distributed systems such as supercomputers. To enable
non-blocking algorithms, we present ways to perform scalable atomic
operations on objects in remote memory via remote direct memory access
and pointer compression. As a solution to the problem of
concurrent-safe reclamation of memory in a distributed system, we
adapt Epoch-Based Memory Reclamation to distributed memory and
implement it such that it supports global-view programming. This
construct is designed and implemented for the Chapel programming
language but can be adapted and generalized to work on other languages
and libraries.

      </font></small>
    </td>
  </tr>

  <tr><td>&nbsp;</td></tr>

  <tr>
    <td valign="top"><small>3:20&ndash;3:35:&nbsp;</small></td>
    <td><small><b>An Automated Machine Learning Approach for Data
    Locality Optimizations in Chapel</b>
       [<a href = "CHIUW/2020/Kayraklioglu.pdf">slides</a> | <a href = "https://youtu.be/VC8xQOF6ER8">video w/ Q&amp;A</a>]
    </small></td>
  </tr>
  <tr>
    <td></td><td><small>
        <u>Engin Kayraklioglu</u> (<i>Cray, a Hewlett Packard Enterprise company</i>),
        Tarek El-Ghazawi (<i>The George Washington University</i>)
    </small></td>
  </tr>

  <tr>
    <td></td><td><small><b>Abstract:</b> <font color="DarkBlue">

This talk will cover a machine learning approach for automated
locality optimizations in Chapel. With this approach, applications
that do not have any optimizations specific to distributed memory can
scale with almost no programmer effort.

      </font></small>
    </td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>


  <tr>
    <td></td><td><center><b>Open Session</b><br>
    <small>Session chair: Michael Ferguson (<i>Cray/HPE</i>)</small></center></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td valign="top"><small>3:35&ndash;?:??:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</small></td>
    <td><small><b>Open Discussion Session</b>
 </small></td>
  </tr>
  <tr>
    <td></td>
    <td><small>This final session is designed to support open
        discussion and interaction among the CHIUW attendees, similar
        to what we'd normally do over dinner and drinks, though the
        precise format will be TBD depending on the number and energy
        of participants.  If you would like to propose something
        specific here, please let us know.</small></td>
  </tr>


  <tr>
    <td>&nbsp;</td>
  </tr>


</table>

<p>&nbsp;</p>



<center>
<p>
<a id = "codeday">
<big><u><b>Chapel Coding Day</b></u></big><br>
</a>
</p>
</center>

<table summary = "description of CHIUW 2020's coding day">

  <tr>
    <td>&nbsp;</td>
  </tr>

  <tr><td valign="top"><small>TBD:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</small></td><td><small><b>Chapel Coding Day</b></small></td></tr>

  <tr><td></td><td><small>Traditionally, CHIUW has included a second
        day designed to support coding together while we're in one
        location.  But since we won't be co-located this year, any
        coding day will either take place later, or in small
        individually-scheduled groups depending on the level of
        interest (a good topic of discussion for the final session on
        the 22nd).
    </small></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
  </tr>

</table>


<p>
&nbsp;
</p>

<p>
<a id = "committee">
<b><big>Committee</big></b><br>
</a>
</p>
<div class="indent">
<p>
<b>General Chair:</b>
<ul>
<li> Benjamin Robbins, <i>Cray, a Hewlett Packard Enterprise Company</i><br>
</ul>

<b>Steering Committee:</b>
<ul>
<li> Michael Ferguson, <i>Cray, a Hewlett Packard Enterprise Company</i><br>
<li> Mike Merrill, <i>U.S. DOD</i>
<li> Nikhil Padmanabhan, <i>Yale University</i>
<li> Marcin Zalewski, <i>NVIDIA</i>
</ul>
</p>

<b>Program Committee:</b>
<ul>
<li> Brad Chamberlain (chair), <i>Cray, a Hewlett Packard Enterprise Company</i><br>
<li> Cathie Olschanowsky (co-chair), <i>Boise State University</i>
<li> Maryam Dehnavi, <i>University of Toronto</i> 
<li> Clemens Grelck, <i>University of Amsterdam</i>
<li> Paul H. Hargrove, <i>Lawrence Berkeley National Laboratory</i>
<li> Engin Kayraklioglu, <i>Cray, a Hewlett Packard Enterprise Company</i><br>
<li> Milind Kulkarni, <i>Purdue University</i>
<li> Josh Milthorpe, <i>Australian National University</i>
<li> Tyler Simon, <i>UMBC</i>
<li> Christian Terboven, <i>RWTH Aachen University</i>
<li> Rich Vuduc, <i>Georgia Tech</i>
<li> Marcin Zalewski, <i>NVIDIA</i>
</ul>
</div>

<p>&nbsp;</p>

<p>
<small><a href = "CHIUW2020-cfp.html"><b>Call For Participation</b></a> (for
archival purposes)</small>
</p>

<?php include("stdfooter.html");?>
